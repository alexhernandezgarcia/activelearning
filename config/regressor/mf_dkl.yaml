_target_: regressor.dkl.DeepKernelRegressor

checkpoint: proxy

surrogate:
  _target_: model.gp_models.SingleTaskMultiFidelitySVGP
  max_shift: 0
  mask_size: 0
  bootstrap_ratio: null
  min_num_train: 128
  task_noise_init: 0.5
  lengthscale_init: 0.7
  gp_lr: 1e-3
  enc_lr: 1e-3
  bs: ${model.batch_size}
  eval_bs: 32
  num_epochs: 512
  holdout_ratio: 0.1 #0.2
  early_stopping: True
  patience: 32
  eval_period: 5
  feature_dim: 16
  out_dim: 1
  num_inducing_points: 64
  learn_inducing_points: True
  encoder_wd: 1e-4
  mll_beta: 1e-2
  lengthscale_prior:
    _target_: gpytorch.priors.NormalPrior
    loc: ${regressor.surrogate.lengthscale_init}
    scale: 1e-2
  noise_constraint:
    _target_: gpytorch.constraints.GreaterThan
    lower_bound: 1e-4

# encoder:
#   _target_: lambo.models.lm_elements.LanguageModel
#   name: mlm_cnn

#   model:
#     _target_: lambo.models.shared_elements.mCNN
#     # tokenizer: ${tokenizer}
#     max_len: ${env.max_len}
#     embed_dim: 64
#     latent_dim: 16
#     out_dim: 16
#     kernel_size: 5
#     p: 0.
#     layernorm: True
#     max_len_delta: 0

#   batch_size: 32
#   num_epochs: 128
#   patience: 32
#   lr: 1e-3
#   max_shift: 0
#   mask_ratio: 0.125