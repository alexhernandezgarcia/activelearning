# @package _global_

defaults:
  # - _self_
  - env: grid
  # Required so that it can be set up in the environment and used for scoring
  # - true_oracle: branin
  # - oracle@_oracle_dict.1: branin
  - oracle@_oracle_dict.1: branin1
  - oracle@_oracle_dict.2: branin2
  - oracle@_oracle_dict.3: branin3
  - gflownet: trajectorybalance
  - user: nikita
  - proxy: mf_kg_gp # mes_gp #mf_mes_svgp #mes_gp  #mf_mes_gp #gp_ucb #mf_mes_dkl mes_gp
  - dataset: dataset
  - regressor: mf_gp #mf_dkl_linear #mf_svgp #mf_dkl #sf_svgp #sf_dkl #mf_gp #mf_dkl #sf_gp
  # - model: mlp #regressive
  - logger: wandb

# proxy:
#   cost_type: user

# model:
#   beta1: 0.9
#   beta2: 0.99

# regressor:
#   optim: adam
#   surrogate:
#     eval_period: 1
#     num_epochs: 2048
#     patience: 100
#     num_inducing_points: 64
#   encoder_obj: mlm
#   lr_sched_type: plateau #step

logger:
  # resume: True 
  # logdir: 
  #   root: /network/scratch/n/nikita.saxena/logs/activelearning/2023-04-06_18-31-55
  # run_id: 694bvn10
  project_name: "KG"
  lightweight: False
  plot:
    period: 3000
    first_it: True
  test:
    period: 3000
    n: 30000
    first_it: True
  oracle:
    period: -1
  # ckpts:
  #   policy:
  #     period: 1000
  do:
    times: False
    online: True
  tags:
    # - r(x) = (80 + x)
    # - r(x) = 10x
    - branin
    - gp
    - correct_data
    - fid_embed
    # - test svgp_dkl
    # - single_fidelity
    # - mf-mes
    # - ucb
    # - cum_cost
    # - 100x100

env:
  corr_type: None
  proxy_state_format: state #state_fidIdx FOR DKL, state for GP
  reward_func: power #shift power
  reward_beta: 1 #1 #80
  length: 100
  rescale: 15 
  reward_norm: 1 #1e-1 #1
  buffer:
    train:
      path: null
      # /home/mila/n/nikita.saxena/activelearning/storage/amp/data_train.csv
      n: null
      type: null
      seed: null
      output_csv: null 
    test:
      path: null #data_test.csv
      type: all
      output_pkl: buffer_data_test.csv
      n: null
      seed: null
      output_csv: null 
    

gflownet:
  active_learning: True
  sample_only: True
  random_action_prob: 0.0
  optimizer:
    lr: 5e-4
    lr_z_mult: 20
    n_train_steps: 10000
    batch_size: 16
  policy:
    forward:
      type: mlp
      n_hid: 2048
      n_layers: 2
      checkpoint: fp
    backward:
      type: mlp
      shared_weights: True
  pct_offline: 0.0
  oracle:
    n: 500

dataset:
  normalize_data: True
  n_samples: 300
  train_fraction: 0.8
  split: all_train #random all_train
  dataloader:
    train:
      batch_size: 256
    test:
      batch_size: 256
  path:
    type: mf #mf sf
    oracle_dataset: 
    # UNCOMMENT FOR GP
    # COMMENT FOR DKL BECAUSE NEED INDUCING POINTS
      fid_type: random
      train: 
        path: /home/mila/n/nikita.saxena/activelearning/storage/branin/mf_300.csv
        # path: /home/mila/n/nikita.saxena/activelearning/storage/branin/lower_quad_nfid3_100x100.csv
        get_scores: True
      # train: null
      test: null
# Number of objects to sample at the end of training
# Sample 5*K and choose topK
n_samples: 30
# Random seeds
seed: 0
# Device
device: cuda
# Float precision
float_precision: 64
#It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444
al_n_rounds: 10 #1
do_figure: True
multifidelity:
  fid_embed: one_hot
  fid_embed_dim: None
  proxy: True
  rescale: 10
  candidate_set_path: null
budget: 450
  # /home/mila/n/nikita.saxena/activelearning/storage/branin/mf_train50.csv
  #  /home/mila/n/nikita.saxena/activelearning/storage/grid/nfid3_lower_quad.csv
  # /home/mila/n/nikita.saxena/activelearning/storage/grid/nfid3.csv
  # fixed_cost: 1e-6

# Hydra config
hydra:
  # See: https://hydra.cc/docs/configure_hydra/workdir/
  run:
    dir: ${user.logdir.root}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    # See: https://hydra.cc/docs/upgrades/1.1_to_1.2/changes_to_job_working_dir/
    # See: https://hydra.cc/docs/tutorials/basic/running_your_app/working_directory/#disable-changing-current-working-dir-to-jobs-output-dir
    chdir: True