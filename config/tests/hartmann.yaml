# @package _global_
# Hartmann test experiment

defaults:
  - override /dataset: hartmann
  - override /oracle: hartmann
  - override /env: grid
  - override /sampler: greedy
  - override /selector: selector
  - override /surrogate: gp
  - override /acquisition: botorch_mve
  - override /user: default
  - override /logger: base #wandb
  - override /plotter: null #cime4r_branin # not working with gflownet because it produces new samples

logger:
  project_name: test_hartmann
  run_name: ${env.length}_${sampler.id}_${surrogate.id}_${acquisition.id}

dataset:
  train_path: ${user.data.root}/hartmann/data_train.csv
  batch_size: 16384

env:
  # Number of cells per dimension
  length: 10
  n_dim: 6
  # Mapping coordinates
  cell_min: -1
  cell_max: 1

sampler: 
  conf:
    agent:
      random_action_prob: 0.001 # 0.01 #0.001
      optimizer:
        lr: 5e-4
        n_train_steps: 5000 # 10000
    logger:
      do:
        online: True
      project_name: "test_hartmann_gflownet"
      run_name: "identity_lr5e-4 newdata"
    proxy:
      # Reward function: power or boltzmann
      # boltzmann: exp(-1.0 * reward_beta * proxy)
      # power: (-1.0 * proxy / reward_norm) ** self.reward_beta
      # identity: proxy
      reward_func: power
      # Minimum reward
      reward_min: 1e-8
      reward_function_kwargs: 
        # Beta parameter of the reward function
        beta: 1.0
        # Reward normalization for "power" reward function
        # norm: 1.0

device: cpu
float_precision: 32
budget: 10
n_samples: 5
seed: 31415
maximize: False
