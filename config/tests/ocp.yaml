# @package _global_
# OCP test experiment

defaults:
  - override /dataset: ocp
  - override /oracle: ocp
  - override /env: crystal_surface
  - override /sampler: random_gflownet # surface_gflownet # greedy # random # random_gflownet
  - override /selector: score # selector # score
  - override /surrogate: svdkl_kernel_wrapper
  - override /acquisition: botorch_mve #botorch_mve #botorch_ei #botorch_nei
  - override /user: default
  - override /logger: wandb
  # cime4r export significantly increases runtime --> only use when really needed; 
  # note: does not work when using gflownet yet, because gflownet produces new samples --> TODO
  - override /plotter: null # cime4r_ocp

logger:
  project_name: test_ocp_training
  run_name: ${sampler.id}_${surrogate.id}_samples-${n_samples}_${acquisition.id}_${seed}_max

dataset:
  checkpoint_path: /network/scratch/a/alexandre.duval/ocp/runs/4648581/checkpoints/best_checkpoint.pt
  data_path: /network/scratch/a/alexandre.duval/ocp/runs/4657270/deup_dataset
  # we want to split the training set into 10% (train) and 90% (validation) for testing purposes
  train_fraction: 0.1

surrogate:
  mll_args: 
    # number of training data instances
    num_data: 4059 #40593 
  feature_extractor:
    n_input: 352
    n_hidden: [265, 512, 265]
    n_output: 16
  train_epochs: 20
  lr: 0.01

device: cuda
float_precision: 64
budget: 10
n_samples: 100
seed: 98765
maximize: False
