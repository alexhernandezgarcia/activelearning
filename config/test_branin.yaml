defaults:
  # - _self_ # with _self_ the overrides don't seem to work...
  - dataset: branin
  - env: grid
  - oracle: branin
  - sampler: random_gflownet #random_gflownet #greedy #gflownet #random
  - selector: score #selector #score
  - surrogate: gp
  - acquisition: botorch_mve
  - user: default
  - logger: wandb #base #wandb
  - plotter: null #cime4r_branin # not working with gflownet because it produces new samples

logger:
  project_name: test_branin
  run_name: ${env.length}_random_gp_mve

dataset:
  train_path: ~/activelearning/data/branin/data_100_train.csv
  
env:
  # Number of cells per dimension
  length: 100 
  # Mapping coordinates
  cell_min: -1
  cell_max: 1

sampler: 
  conf:
    agent:
      random_action_prob: 0.0 # 0.01
      optimizer:
        lr: 5e-4
        n_train_steps: 500 #5000 # 10000
    logger:
      do:
        online: False #True
      project_name: "test_gflownet"
      run_name: "identity_lr5e-4"
    proxy:
      # Reward function: power or boltzmann
      # boltzmann: exp(1.0 * reward_beta * proxy)
      # power: (1.0 * proxy / reward_norm) ** self.reward_beta
      # identity: proxy
      reward_function: power
      # Minimum reward
      reward_min: 1e-8
      reward_function_kwargs: 
        # Beta parameter of the reward function
        beta: 1.0
        # Reward normalization for "power" reward function
        # norm: 1.0
      

device: cpu
float_precision: 32
budget: 10
n_samples: 5
seed: 31415
maximize: False


# Hydra config
hydra:
  # See: https://hydra.cc/docs/configure_hydra/workdir/
  run:
    dir: ${user.logdir.root}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: ${user.logdir.root}/multirun/${now:%Y-%m-%d_%H-%M-%S}
  job:
    # See: https://hydra.cc/docs/upgrades/1.1_to_1.2/changes_to_job_working_dir/
    # See: https://hydra.cc/docs/tutorials/basic/running_your_app/working_directory/#disable-changing-current-working-dir-to-jobs-output-dir
    chdir: True
