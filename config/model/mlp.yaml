_target_: model.mlp.MLP

activation: 'relu'
num_output: 1
hidden_dim: 64
dropout_prob: 0.1
num_layer: 4