_target_: model.mlp.MLP

activation: 'relu'
num_output: 1
n_hid: 64
dropout_prob: 0.1
n_layers: 4