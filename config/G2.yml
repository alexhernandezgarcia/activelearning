# General
test_mode: False
debug: False
run_num: 0
explicit_run_enumeration: True
machine: "cluster"
device: "cpu"
workdir: !!null
# Seeds
seeds:
  sampler: 0
  model: 0
  dataset: 0
  toy_oracle: 0
# Dataset
dataset:
  oracle: "nupack energy"
  type: "toy"
  init_length: 100
  dict_size: 4
  variable_length: True
  min_length: 10
  max_length: 60
  sample_tasks: 1
# AL
al:
  sample_method: "random"
  query_mode: "energy"
  hyperparams_learning: False
  n_iter: 20
  query_selection: "clustering"
  minima_dist_cutoff: 0.25
  energy_uncertainty_tradeoff: 0
  queries_per_iter: 100
  mode: "training"
  q_batch_size: 32
  buffer_size: 10000
  episodes: 1
  action_state_size: 9
# Querier
querier: 
  model_state_size: 30
  opt: "SGD"
  momentum: 0.95
  model_ckpt: !!null
  latent_space_width: 10
# GFlowNet
gflownet:
  device: "cpu"
  model_ckpt: !!null #model.pt
  progress: 1
  opt: "adam"
  adam_beta1: 0.9
  adam_beta2: 0.999
  momentum: 0.9
  mbsize: 16
  train_to_sample_ratio: 1
  n_hid: 256
  n_layers: 2
  n_iter: 200
  n_samples: 10000
  num_empirical_loss: 200000
  batch_reward: 1
  bootstrap_tau: 0.0
  clip_grad_norm: 0.0
  annealing: True
  post_annealing_samples: 100
  post_annealing_time: 1000
  min_word_len: 1
  max_word_len: 1
  comet:
    project: !!null #aptamer-al-mk
    tags:
      - testing
  early_stopping: 0.1
  ema_alpha: 0.5
  learning_rate: 0.0001
  ckpt_period: 100
  reward_beta_init: 1
  reward_beta_mult: 1.25
  reward_beta_period: 100
  reward_max: 10000
# Proxy model
proxy:
  model_type: "mlp"
  training_parallelism: False
  ensemble_size: 5
  width: 256
  n_layers: 4
  mbsize: 10
  max_epochs: 200
  shuffle_dataset: True
# MCMC
mcmc:
  sampling_time: 10000
  num_samplers: 20
  stun_min_gamma: -3
  stun_max_gamma: 1
