{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biotite.sequence as biotite_seq\n",
    "import biotite.sequence.align as align\n",
    "substitution_matrix = align.SubstitutionMatrix.std_protein_matrix()\n",
    "import glob\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import coolwarm\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_pkl_file(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.pkl'):\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "def get_diversity(seqs):\n",
    "    sample_states1 = torch.tensor(seqs)\n",
    "    sample_states2 = sample_states1.clone()\n",
    "    dist_matrix = torch.cdist(sample_states1, sample_states2, p=2)\n",
    "    dist_upper_triangle = torch.triu(dist_matrix, diagonal=1)\n",
    "    dist_vector = dist_upper_triangle[dist_upper_triangle != 0]\n",
    "    return dist_vector\n",
    "\n",
    "# def get_novelty(dataset_seqs, sampled_seqs):\n",
    "#     sampled_seqs = [biotite_seq.ProteinSequence(seq) for seq in sampled_seqs]\n",
    "#     dataset_seqs = [biotite_seq.ProteinSequence(seq) for seq in dataset_seqs]\n",
    "#     min_dists = []\n",
    "#     for sample in sampled_seqs:\n",
    "#         dists = []\n",
    "#         sample_repeated = itertools.repeat(sample, len(dataset_seqs))\n",
    "#         for s_0, x_0 in zip(sample_repeated, dataset_seqs):\n",
    "#              alignment = align.align_optimal(s_0, x_0, substitution_matrix, local=False, max_number=1)[0]\n",
    "#              dists.append(align.get_sequence_identity(alignment))\n",
    "#         min_dists.append(min(dists))\n",
    "#     min_dists = torch.FloatTensor(min_dists)\n",
    "#     return torch.mean(min_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARTMANN\n",
    "oracle_maximize = True\n",
    "k = 10\n",
    "AL_BATCH_SIZE = 10\n",
    "\n",
    "sf_logdir1 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-05_01-08-33\"\n",
    "sf_run_path1 = \"alexhg/Hartmann budget data set/nioe5ca4\"\n",
    "# 2 and 3 were of different seeds but started at the same time so logged to the same folder\n",
    "sf_logdir2 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-04_06-27-13\"\n",
    "sf_run_path2 = \"alexhg/Hartmann budget data set/u3jlu0gs\"\n",
    "sf_logdir3 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-04_06-27-13\"\n",
    "sf_run_path3 = \"nikita0209/AMP-DKL/zgoc6a5q\"\n",
    "sf_logdirs = [sf_logdir1, sf_logdir2, sf_logdir3]\n",
    "sf_run_paths = [sf_run_path1, sf_run_path2, sf_run_path3]\n",
    "\n",
    "# mf_train_dataset = \"/home/mila/n/nikita.saxena/activelearning/storage/amp/mf/data_train.csv\"\n",
    "# mf_test_dataset = \"/home/mila/n/nikita.saxena/activelearning/storage/amp/mf/data_test.csv\"\n",
    "mf_logdir1 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-05_10-51-53\"\n",
    "mf_run_path1 = \"alexhg/Hartmann budget data set/bytcboio\"\n",
    "mf_logdir2 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-04_06-27-11\"\n",
    "mf_run_path2 = \"alexhg/Hartmann budget data set/n6i5yw72\"\n",
    "mf_logdir3 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-04_06-27-12\"\n",
    "mf_run_path3 = \"alexhg/Hartmann budget data set/wkimrg0l\"\n",
    "mf_logdirs = [mf_logdir1, mf_logdir2, mf_logdir3]\n",
    "mf_run_paths = [mf_run_path1, mf_run_path2, mf_run_path3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRANIN\n",
    "oracle_maximize = False\n",
    "k = 50\n",
    "AL_BATCH_SIZE = 30\n",
    "\n",
    "sf_logdir1 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-03_06-35-40\"\n",
    "sf_run_path1 = \"alexhg/Branin budget data set/p6nu2nzx\"\n",
    "sf_logdir2 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-03_06-32-45\"\n",
    "sf_run_path2 = \"alexhg/Branin budget data set/yvk5tox2\"\n",
    "sf_logdir3 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-03_18-49-33\"\n",
    "sf_run_path3 = \"alexhg/Branin budget data set/27japxej\"\n",
    "sf_logdirs = [sf_logdir1, sf_logdir2, sf_logdir3]\n",
    "sf_run_paths = [sf_run_path1, sf_run_path2, sf_run_path3]\n",
    "\n",
    "mf_logdir1 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-04_22-24-48\"\n",
    "mf_run_path1 = \"alexhg/Branin budget data set/cijnbh4w\"\n",
    "mf_logdir2 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-03_06-41-16\"\n",
    "mf_run_path2 = \"alexhg/Branin budget data set/lwzlgxvj\"\n",
    "mf_logdir3 = \"/network/scratch/h/hernanga/logs/gflownet/2023-05-03_06-41-50\"\n",
    "mf_run_path3 = \"alexhg/Branin budget data set/g557nx3y\"\n",
    "mf_logdirs = [mf_logdir1, mf_logdir2, mf_logdir3]\n",
    "mf_run_paths = [mf_run_path1, mf_run_path2, mf_run_path3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(logdir, run_path, oracle_maximize, is_mf=False, eps=1e-3):\n",
    "\n",
    "    pkl_file = find_pkl_file(logdir)\n",
    "    culm_pkl = pd.read_pickle(pkl_file)\n",
    "    culm_samples = culm_pkl['cumulative_sampled_samples']\n",
    "    culm_energies = culm_pkl['cumulative_sampled_energies']\n",
    "\n",
    "\n",
    "    metric_diversity = []\n",
    "    metric_energy = []\n",
    "    metric_cost = []\n",
    "    # mean_energy_from_wandb = run.history(keys=[\"mean_energy_top{}\".format(k)])\n",
    "    # mean_energy_from_wandb = mean_energy_from_wandb[\"mean_energy_top{}\".format(k)].values\n",
    "    run = api.run(run_path)\n",
    "    post_al_cum_cost = run.history(keys=[\"post_al_cum_cost\"])\n",
    "    post_al_cum_cost = np.unique(post_al_cum_cost['post_al_cum_cost'])\n",
    "\n",
    "    steps = np.arange(start = AL_BATCH_SIZE, stop = len(culm_samples), step = AL_BATCH_SIZE, dtype=int)\n",
    "    for idx, upper_bound in enumerate(steps):\n",
    "        culm_samples_curr_iter = culm_samples[0:upper_bound]\n",
    "        culm_sampled_energies_curr_iter = culm_energies[0:upper_bound]\n",
    "\n",
    "        idx_topk = torch.argsort(culm_sampled_energies_curr_iter, descending=oracle_maximize)[:k].tolist()\n",
    "        samples_topk = [culm_samples_curr_iter[i] for i in idx_topk]\n",
    "        energies_topk = [culm_sampled_energies_curr_iter[i] for i in idx_topk]\n",
    "        mean_energy_topk = torch.mean(torch.FloatTensor(energies_topk))\n",
    "        # diff = abs(mean_energy_topk-mean_energy_from_wandb[idx])\n",
    "        # if diff>eps:\n",
    "            # print(\"ERROR: energy from wandb does not match for the {}th iteration\".format(idx))\n",
    "        metric_energy.append(mean_energy_topk.numpy())\n",
    "        mean_diversity_topk = get_diversity(samples_topk)\n",
    "        metric_diversity.append(mean_diversity_topk.numpy())\n",
    "        metric_cost.append(post_al_cum_cost[idx])\n",
    "\n",
    "    # PLOT METRICS\n",
    "    reward = np.array(metric_energy)\n",
    "    diversity = np.array(metric_diversity)\n",
    "    cost = np.array(metric_cost)\n",
    "\n",
    "    return reward, diversity, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     setattr(sys.modules[__name__], \"sf{}\".format(i+1), 32+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over 1, 2, 3 and create three variables sf1, sf2, sf3\n",
    "import sys\n",
    "max_iter = 0\n",
    "for i in range(3):\n",
    "    setattr(sys.modules[__name__], \"sf_tuple{}\".format(i+1), get_performance(sf_logdirs[i], sf_run_paths[i], oracle_maximize=False))\n",
    "    setattr(sys.modules[__name__], \"mf_tuple{}\".format(i+1), get_performance(sf_logdirs[i], sf_run_paths[i], oracle_maximize=False))\n",
    "    max_iter = max(max_iter, len(getattr(sys.modules[__name__], \"sf_tuple{}\".format(i+1))[0]))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        sf_tuple = getattr(sys.modules[__name__], \"sf_tuple{}\".format(i+1))\n",
    "        mf_tuple = getattr(sys.modules[__name__], \"mf_tuple{}\".format(j+1))\n",
    "        sf_reward = sf_tuple[0]\n",
    "        sf_diversity = sf_tuple[1]\n",
    "        sf_cost = sf_tuple[2]\n",
    "        mf_reward = mf_tuple[0]\n",
    "        mf_diversity = mf_tuple[1]\n",
    "        mf_cost = mf_tuple[2]\n",
    "        sf_reward = np.append(sf_reward, np.repeat(sf_reward[-1], max_iter-len(sf_reward)))\n",
    "        sf_diversity = np.append(sf_diversity, np.repeat(sf_diversity[-1], max_iter-len(sf_diversity)))\n",
    "        sf_cost = np.append(sf_cost, np.repeat(sf_cost[-1], max_iter-len(sf_cost)))\n",
    "        mf_reward = np.append(mf_reward, np.repeat(mf_reward[-1], max_iter-len(mf_reward)))\n",
    "        mf_diversity = np.append(mf_diversity, np.repeat(mf_diversity[-1], max_iter-len(mf_diversity)))\n",
    "        mf_cost = np.append(mf_cost, np.repeat(mf_cost[-1], max_iter-len(mf_cost)))\n",
    "        setattr(sys.modules[__name__], \"sf_tuple{}\".format(i+1), (sf_reward, sf_diversity, sf_cost))\n",
    "        setattr(sys.modules[__name__], \"mf_tuple{}\".format(j+1), (mf_reward, mf_diversity, mf_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['reward', 'diversity', 'cost']\n",
    "for metric in metrics:\n",
    "    setattr(sys.modules[__name__], \"cum_sf_{}\".format(metric), np.stack([getattr(sys.modules[__name__], \"sf_tuple{}\".format(i+1))[metrics.index(metric)] for i in range(3)], axis=0))\n",
    "    setattr(sys.modules[__name__], \"sf_{}\".format(metric), np.mean(getattr(sys.modules[__name__], \"cum_sf_{}\".format(metric)), axis=0))\n",
    "    setattr(sys.modules[__name__], \"std_sf_{}\".format(metric), np.std(getattr(sys.modules[__name__], \"cum_sf_{}\".format(metric)), axis=0))\n",
    "    setattr(sys.modules[__name__], \"cum_mf_{}\".format(metric), np.stack([getattr(sys.modules[__name__], \"mf_tuple{}\".format(i+1))[metrics.index(metric)] for i in range(3)], axis=0))\n",
    "    setattr(sys.modules[__name__], \"mf_{}\".format(metric), np.mean(getattr(sys.modules[__name__], \"cum_mf_{}\".format(metric)), axis=0))\n",
    "    setattr(sys.modules[__name__], \"std_mf_{}\".format(metric), np.std(getattr(sys.modules[__name__], \"cum_mf_{}\".format(metric)), axis=0))\n",
    "\n",
    "# cum_sf_reward = np.stack([sf_tuple1[0], sf_tuple2[0], sf_tuple3[0]], axis=0)\n",
    "# avg_sf_reward = np.mean(cum_sf_reward, axis=0)\n",
    "# std_sf_reward = np.std(cum_sf_reward, axis=0)\n",
    "\n",
    "# cum_sf_diversity = np.stack([sf_tuple1[1], sf_tuple2[1], sf_tuple3[1]], axis=0)\n",
    "# avg_sf_diversity = np.mean(cum_sf_diversity, axis=0)\n",
    "# std_sf_diversity = np.std(cum_sf_diversity, axis=0)\n",
    "\n",
    "# cum_sf_cost = np.stack([sf_tuple1[2], sf_tuple2[2], sf_tuple3[2]], axis=0)\n",
    "# avg_sf_cost = np.mean(cum_sf_cost, axis=0)\n",
    "# std_sf_cost = np.std(cum_sf_cost, axis=0)\n",
    "\n",
    "# cum_mf_reward = np.stack([mf_tuple1[0], mf_tuple2[0], mf_tuple3[0]], axis=0)\n",
    "# avg_mf_reward = np.mean(cum_mf_reward, axis=0)\n",
    "# std_mf_reward = np.std(cum_mf_reward, axis=0)\n",
    "\n",
    "# cum_mf_diversity = np.stack([mf_tuple1[1], mf_tuple2[1], mf_tuple3[1]], axis=0)\n",
    "# avg_mf_diversity = np.mean(cum_mf_diversity, axis=0)\n",
    "# std_mf_diversity = np.std(cum_mf_diversity, axis=0)\n",
    "\n",
    "# cum_mf_cost = np.stack([mf_tuple1[3], mf_tuple2[3], mf_tuple3[3]], axis=0)\n",
    "# avg_mf_cost = np.mean(cum_mf_cost, axis=0)\n",
    "# std_mf_cost = np.std(cum_mf_cost, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single subplot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the two line curves\n",
    "mf_plot = ax.plot(mf_cost, mf_reward, color='blue', label='Multi-Fidelity')\n",
    "sf_plot = ax.plot(sf_cost, sf_reward, color='red', label='Highest-Fidelity')\n",
    "ax.fill_between(sf_cost, sf_reward-std_sf_reward, sf_reward+std_sf_reward, alpha=0.2, color='blue')\n",
    "ax.fill_between(mf_cost, mf_reward-std_mf_reward, mf_reward+std_mf_reward, alpha=0.2, color='red')\n",
    "\n",
    "# Set the title and axis labels\n",
    "ax.set_title('Hartmann')\n",
    "ax.set_xlabel('Cost')\n",
    "ax.set_ylabel('Top{} Reward'.format(k))\n",
    "# add grid\n",
    "ax.grid(True, linestyle='--')\n",
    "# convert cost labels to exponential\n",
    "ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Create a single ScalarMappable object for the colorbar\n",
    "div_norm = Normalize(vmin=np.min([sf_diversity, mf_diversity]), vmax=np.max([sf_diversity, mf_diversity]))\n",
    "div_cmap = coolwarm\n",
    "div_cmap = 'viridis'\n",
    "sm = plt.cm.ScalarMappable(cmap=div_cmap, norm=div_norm)\n",
    "# sm = plt.cm.ScalarMappable(cmap='viridis', norm=div_norm)\n",
    "\n",
    "\n",
    "# Add scatter plots for both line curves and shade the points by diversity\n",
    "mf_scatter = ax.scatter(mf_cost, mf_reward, c=mf_diversity, cmap=div_cmap, norm=div_norm, marker='^')\n",
    "sf_scatter = ax.scatter(sf_cost, sf_reward, c=sf_diversity, cmap=div_cmap, norm=div_norm)\n",
    "\n",
    "# Add a colorbar for the ScalarMappable object\n",
    "cbar = fig.colorbar(sm)\n",
    "\n",
    "# Set the label for the colorbar\n",
    "cbar.ax.set_ylabel('Diversity')\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
