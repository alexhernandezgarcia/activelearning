{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'test.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  _target_: dataset.grid.BraninDatasetHandler\n",
      "  grid_size: 100\n",
      "  normalize_scores: true\n",
      "  train_fraction: 1.0\n",
      "  batch_size: 16\n",
      "  shuffle: true\n",
      "  train_path: ~/activelearning/my_package/storage/branin/data_100_train.csv\n",
      "  test_path: null\n",
      "oracle:\n",
      "  _target_: oracle.oracle.Branin\n",
      "  fidelity: 1\n",
      "  do_domain_map: true\n",
      "filter:\n",
      "  _target_: filter.filter.Filter\n",
      "sampler:\n",
      "  conf:\n",
      "    state_flow: null\n",
      "    policy:\n",
      "      forward:\n",
      "        _target_: gflownet.policy.base.Policy\n",
      "        config:\n",
      "          type: mlp\n",
      "          n_hid: 128\n",
      "          n_layers: 2\n",
      "          checkpoint: null\n",
      "          reload_ckpt: false\n",
      "          is_model: false\n",
      "      backward:\n",
      "        _target_: gflownet.policy.base.Policy\n",
      "        config: null\n",
      "      shared: null\n",
      "    env:\n",
      "      _target_: gflownet.envs.grid.Grid\n",
      "      id: grid\n",
      "      func: corners\n",
      "      n_dim: 2\n",
      "      length: 100\n",
      "      max_increment: 1\n",
      "      max_dim_per_action: 1\n",
      "      cell_min: 0\n",
      "      cell_max: 0.99\n",
      "      buffer:\n",
      "        train: null\n",
      "        test: null\n",
      "      reward_func: power\n",
      "      reward_min: 1.0e-08\n",
      "      reward_beta: 5.0\n",
      "      reward_norm: 1.0\n",
      "      reward_norm_std_mult: 0.0\n",
      "      proxy_state_format: oracle\n",
      "      skip_mask_check: false\n",
      "      conditional: false\n",
      "      continuous: false\n",
      "    agent:\n",
      "      _target_: gflownet.gflownet.GFlowNetAgent\n",
      "      seed: 0\n",
      "      optimizer:\n",
      "        z_dim: 16\n",
      "        loss: trajectorybalance\n",
      "        lr: 0.0005\n",
      "        lr_decay_period: 1000000\n",
      "        lr_decay_gamma: 0.5\n",
      "        lr_z_mult: 100\n",
      "        method: adam\n",
      "        early_stopping: 0.0\n",
      "        ema_alpha: 0.5\n",
      "        adam_beta1: 0.9\n",
      "        adam_beta2: 0.999\n",
      "        sgd_momentum: 0.9\n",
      "        batch_size:\n",
      "          forward: 10\n",
      "          backward_dataset: 0\n",
      "          backward_replay: 0\n",
      "        train_to_sample_ratio: 1\n",
      "        n_train_steps: 1000\n",
      "        bootstrap_tau: 0.0\n",
      "        clip_grad_norm: 0.0\n",
      "      batch_reward: true\n",
      "      mask_invalid_actions: true\n",
      "      temperature_logits: 1.0\n",
      "      random_action_prob: 0.01\n",
      "      pct_offline: 0.0\n",
      "      replay_capacity: 0\n",
      "      replay_sampling: permutation\n",
      "      train_sampling: permutation\n",
      "      num_empirical_loss: 200000\n",
      "      oracle:\n",
      "        'n': 50\n",
      "      sample_only: false\n",
      "      active_learning: false\n",
      "      buffer:\n",
      "        train: null\n",
      "        test: null\n",
      "    logger:\n",
      "      _target_: gflownet.utils.logger.Logger\n",
      "      do:\n",
      "        online: true\n",
      "        times: false\n",
      "      project_name: test_gflownet\n",
      "      train:\n",
      "        period: 1\n",
      "      test:\n",
      "        first_it: true\n",
      "        period: 1000\n",
      "        'n': 100\n",
      "        kde:\n",
      "          bandwidth: 0.1\n",
      "          kernel: gaussian\n",
      "        n_top_k: 5000\n",
      "        top_k: 100\n",
      "        top_k_period: -1\n",
      "        n_trajs_logprobs: 10\n",
      "        logprobs_batch_size: 100\n",
      "        logprobs_bootstrap_size: 10000\n",
      "        max_data_logprobs: 100000.0\n",
      "      oracle:\n",
      "        period: 100000\n",
      "        k:\n",
      "        - 1\n",
      "        - 10\n",
      "        - 100\n",
      "      checkpoints:\n",
      "        period: 1000\n",
      "      logdir:\n",
      "        root: activelearning/gflownet/logs\n",
      "        ckpts: activelearning/gflownetckpts\n",
      "        overwrite: true\n",
      "      debug: false\n",
      "      lightweight: false\n",
      "      progress: true\n",
      "      context: '0'\n",
      "      notes: null\n",
      "      tags:\n",
      "      - gflownet\n",
      "      run_name: power5_lr5e-4\n",
      "  _target_: sampler.sampler.GFlowNetSampler\n",
      "surrogate:\n",
      "  _target_: surrogate.surrogate.SingleTaskGPRegressor\n",
      "user:\n",
      "  logdir:\n",
      "    root: activelearning/logs\n",
      "  data:\n",
      "    root: activelearning/data\n",
      "device: cpu\n",
      "float_precision: 32\n",
      "budget: 10\n",
      "n_samples: 5\n",
      "seed: 31415\n",
      "maximize: false\n",
      "\n",
      "{'dataset': {'_target_': 'dataset.grid.BraninDatasetHandler', 'grid_size': 100, 'normalize_scores': True, 'train_fraction': 1.0, 'batch_size': 16, 'shuffle': True, 'train_path': '~/activelearning/my_package/storage/branin/data_100_train.csv', 'test_path': None}, 'oracle': {'_target_': 'oracle.oracle.Branin', 'fidelity': 1, 'do_domain_map': True}, 'filter': {'_target_': 'filter.filter.Filter'}, 'sampler': {'conf': {'state_flow': None, 'policy': {'forward': {'_target_': 'gflownet.policy.base.Policy', 'config': {'type': 'mlp', 'n_hid': 128, 'n_layers': 2, 'checkpoint': None, 'reload_ckpt': False, 'is_model': False}}, 'backward': {'_target_': 'gflownet.policy.base.Policy', 'config': None}, 'shared': None}, 'env': {'_target_': 'gflownet.envs.grid.Grid', 'id': 'grid', 'func': 'corners', 'n_dim': 2, 'length': 100, 'max_increment': 1, 'max_dim_per_action': 1, 'cell_min': 0, 'cell_max': 0.99, 'buffer': {'train': None, 'test': None}, 'reward_func': 'power', 'reward_min': 1e-08, 'reward_beta': 5.0, 'reward_norm': 1.0, 'reward_norm_std_mult': 0.0, 'proxy_state_format': 'oracle', 'skip_mask_check': False, 'conditional': False, 'continuous': False}, 'agent': {'_target_': 'gflownet.gflownet.GFlowNetAgent', 'seed': 0, 'optimizer': {'z_dim': 16, 'loss': 'trajectorybalance', 'lr': 0.0005, 'lr_decay_period': 1000000, 'lr_decay_gamma': 0.5, 'lr_z_mult': 100, 'method': 'adam', 'early_stopping': 0.0, 'ema_alpha': 0.5, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'sgd_momentum': 0.9, 'batch_size': {'forward': 10, 'backward_dataset': 0, 'backward_replay': 0}, 'train_to_sample_ratio': 1, 'n_train_steps': 1000, 'bootstrap_tau': 0.0, 'clip_grad_norm': 0.0}, 'batch_reward': True, 'mask_invalid_actions': True, 'temperature_logits': 1.0, 'random_action_prob': 0.01, 'pct_offline': 0.0, 'replay_capacity': 0, 'replay_sampling': 'permutation', 'train_sampling': 'permutation', 'num_empirical_loss': 200000, 'oracle': {'n': 50}, 'sample_only': False, 'active_learning': False, 'buffer': {'train': None, 'test': None}}, 'logger': {'_target_': 'gflownet.utils.logger.Logger', 'do': {'online': True, 'times': False}, 'project_name': 'test_gflownet', 'train': {'period': 1}, 'test': {'first_it': True, 'period': 1000, 'n': 100, 'kde': {'bandwidth': 0.1, 'kernel': 'gaussian'}, 'n_top_k': 5000, 'top_k': 100, 'top_k_period': -1, 'n_trajs_logprobs': 10, 'logprobs_batch_size': 100, 'logprobs_bootstrap_size': 10000, 'max_data_logprobs': 100000.0}, 'oracle': {'period': 100000, 'k': [1, 10, 100]}, 'checkpoints': {'period': 1000}, 'logdir': {'root': 'activelearning/gflownet/logs', 'ckpts': 'activelearning/gflownetckpts', 'overwrite': True}, 'debug': False, 'lightweight': False, 'progress': True, 'context': '0', 'notes': None, 'tags': ['gflownet'], 'run_name': 'power5_lr5e-4'}}, '_target_': 'sampler.sampler.GFlowNetSampler'}, 'surrogate': {'_target_': 'surrogate.surrogate.SingleTaskGPRegressor'}, 'user': {'logdir': {'root': 'activelearning/logs'}, 'data': {'root': 'activelearning/data'}}, 'device': 'cpu', 'float_precision': 32, 'budget': 10, 'n_samples': 5, 'seed': 31415, 'maximize': False}\n"
     ]
    }
   ],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config = compose(config_name=\"test.yaml\", overrides=[])\n",
    "    print(OmegaConf.to_yaml(config))\n",
    "    print(config)\n",
    "\n",
    "config.sampler.conf.logger.do.online = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = config.device\n",
    "n_iterations = config.budget  # TODO: replace with budget\n",
    "grid_size = config.dataset.grid_size\n",
    "n_samples = config.n_samples\n",
    "maximize = config.maximize\n",
    "\n",
    "from gflownet.utils.common import set_float_precision\n",
    "float_prec = set_float_precision(config.float_precision)\n",
    "\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "# colors = [\"red\", \"blue\", \"green\", \"orange\", \"brown\", \"pink\"]\n",
    "colors = plt.get_cmap(\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.logger import WandBLogger\n",
    "# logger = WandBLogger(project_name=\"test_hartmann\", run_name=\"GFlowNetSampler 100x100 power\")\n",
    "\n",
    "from utils.plotter import PlotHelper\n",
    "# plotter = PlotHelper(logger)\n",
    "plotter = PlotHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.grid import HartmannDatasetHandler\n",
    "from surrogate.surrogate import SingleTaskGPRegressor\n",
    "from sampler.sampler import GreedySampler, RandomSampler\n",
    "from filter.filter import Filter, OracleFilter\n",
    "from oracle.oracle import HartmannOracle\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset_handler = HartmannDatasetHandler(\n",
    "    grid_size=grid_size,\n",
    "    train_path=\"./storage/hartmann/data_train.csv\",\n",
    "    train_fraction=1.0,\n",
    "    float_precision=float_prec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "candidates, xi, yi = dataset_handler.get_candidate_set()\n",
    "candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000000, 6]), (6, 10, 10, 10, 10, 10, 10))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define candidate set\n",
    "xi = np.arange(0, 10)\n",
    "yi = np.arange(0, 10)\n",
    "grid = np.array(np.meshgrid(*[xi, yi] * 3))\n",
    "grid_flat = torch.tensor(grid.T, dtype=torch.float64).reshape(-1, 6)\n",
    "grid_flat.shape, grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.grid import HartmannDatasetHandler\n",
    "from surrogate.surrogate import SingleTaskGPRegressor\n",
    "from sampler.sampler import GreedySampler, RandomSampler\n",
    "from filter.filter import Filter, OracleFilter\n",
    "from oracle.oracle import HartmannOracle\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset_handler = HartmannDatasetHandler(\n",
    "    grid_size=grid_size,\n",
    "    train_path=\"./storage/hartmann/data_train.csv\" % grid_size,\n",
    "    train_fraction=1.0,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "\n",
    "candidate_set, xi, yi = dataset_handler.get_candidate_set()\n",
    "\n",
    "# Oracle\n",
    "oracle = HartmannOracle(\n",
    "    fidelity=1, device=device, float_precision=float_prec\n",
    ")\n",
    "# Filter\n",
    "filter = Filter()\n",
    "# filter = OracleFilter(oracle)\n",
    "\n",
    "if plotter is not None:\n",
    "    fig_oracle, ax_oracle = plotter.plot_function(oracle, candidate_set.clone().to(device), xi=xi, yi=yi)\n",
    "\n",
    "\n",
    "best_scores = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    train_data, test_data = dataset_handler.get_dataloader()\n",
    "    # print(\"iteration\", i)\n",
    "    # Surrogate (e.g., Bayesian Optimization)\n",
    "    # starts with a clean slate each iteration\n",
    "    surrogate = SingleTaskGPRegressor(\n",
    "        float_precision=float_prec, device=device, maximize=maximize\n",
    "    )\n",
    "    surrogate.fit(train_data)\n",
    "\n",
    "    # Sampler (e.g., GFlowNet, or Random Sampler)\n",
    "    # also starts with a clean slate; TODO: experiment with NOT training from scratch\n",
    "    # sampler = RandomSampler(surrogate)\n",
    "    sampler = GreedySampler(surrogate)\n",
    "    # sampler = hydra.utils.instantiate(\n",
    "    #     config.sampler,\n",
    "    #     surrogate=surrogate,\n",
    "    #     device=device,\n",
    "    #     float_precision=float_prec,\n",
    "    #     _recursive_=False,\n",
    "    # )\n",
    "\n",
    "    sampler.fit()  # only necessary for samplers that train a model\n",
    "\n",
    "    samples = sampler.get_samples(\n",
    "        n_samples * 3, candidate_set=candidate_set.clone().to(device)\n",
    "    )\n",
    "    filtered_samples = filter(\n",
    "        n_samples=n_samples, candidate_set=samples.clone(), maximize=maximize\n",
    "    )\n",
    "    \n",
    "    if plotter is not None:\n",
    "        fig_acq, ax_acq = plotter.plot_function(surrogate, candidate_set.clone().to(device), xi=xi, yi=yi)\n",
    "        fig_acq, ax_acq = plotter.plot_samples(filtered_samples, ax_acq, fig_acq)\n",
    "        ax_acq.set_title(\"acquisition fn + selected samples of iteration %i\"%i)\n",
    "        plotter.log_figure(fig_acq, \"acq\")\n",
    "\n",
    "    if ax_oracle is not None:\n",
    "        ax_oracle.scatter(\n",
    "            x=filtered_samples[:, 0].cpu(),\n",
    "            y=filtered_samples[:, 1].cpu(),\n",
    "            c=cm.to_hex(colors(i / n_iterations)),\n",
    "            marker=\"x\",\n",
    "            label=\"it %i\" % i,\n",
    "        )\n",
    "\n",
    "    scores = oracle(filtered_samples.clone())\n",
    "    dataset_handler.update_dataset(filtered_samples.cpu(), scores.cpu())\n",
    "    best_scores.append(scores.min().cpu())\n",
    "\n",
    "if ax_oracle is not None:\n",
    "    fig_oracle.legend()\n",
    "    ax_oracle.set_title(\"oracle fn + samples\")\n",
    "    plotter.log_figure(fig_oracle, key=\"oracle\")\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(best_scores)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"scores\")\n",
    "plt.title(\"Best Score in each iteration\")\n",
    "if plotter is not None:\n",
    "    plotter.log_figure(fig, key=\"best_scores\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
