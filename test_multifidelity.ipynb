{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oracle:\n",
      "  _target_: oracle.oracle.MultiFidelityOracle\n",
      "  oracles:\n",
      "  - branin1:\n",
      "      _target_: gflownet.proxy.box.branin.Branin\n",
      "      fidelity: 1\n",
      "      do_domain_map: true\n",
      "      cost: 100\n",
      "  - branin01:\n",
      "      _target_: gflownet.proxy.box.branin.Branin\n",
      "      fidelity: 0.1\n",
      "      do_domain_map: true\n",
      "      cost: 10\n",
      "  - branin001:\n",
      "      _target_: gflownet.proxy.box.branin.Branin\n",
      "      fidelity: 0.01\n",
      "      do_domain_map: true\n",
      "      cost: 1\n",
      "\n",
      "{'oracle': {'_target_': 'oracle.oracle.MultiFidelityOracle', 'oracles': [{'branin1': {'_target_': 'gflownet.proxy.box.branin.Branin', 'fidelity': 1, 'do_domain_map': True, 'cost': 100}}, {'branin01': {'_target_': 'gflownet.proxy.box.branin.Branin', 'fidelity': 0.1, 'do_domain_map': True, 'cost': 10}}, {'branin001': {'_target_': 'gflownet.proxy.box.branin.Branin', 'fidelity': 0.01, 'do_domain_map': True, 'cost': 1}}]}}\n"
     ]
    }
   ],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config = compose(config_name=\"/oracle/multifidelity.yaml\", overrides=[])\n",
    "    print(OmegaConf.to_yaml(config))\n",
    "    print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle\n",
    "from oracle.oracle import HartmannOracle\n",
    "oracle_1 = HartmannOracle(fidelity=1)\n",
    "oracle_01 = HartmannOracle(fidelity=0.1)\n",
    "oracle_001 = HartmannOracle(fidelity=0.01)\n",
    "\n",
    "\n",
    "# Dataset\n",
    "from dataset.grid import HartmannDatasetHandler\n",
    "dataset_handler = HartmannDatasetHandler(\n",
    "    grid_size=10,\n",
    "    train_path=\"./storage/hartmann/data_train.csv\",\n",
    "    train_fraction=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = dataset_handler.train_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0976, -0.0510, -0.3727, -0.3996, -0.6481, -0.8401, -0.9133, -1.0907,\n",
       "         -1.3106, -1.1868, -1.5895, -1.5020, -1.8520, -1.7501, -2.2254, -2.1657,\n",
       "         -2.5686, -2.4373, -2.8762, -2.7287, -0.1891, -0.1616, -0.0982, -0.0936,\n",
       "         -0.0423], dtype=torch.float64),\n",
       " tensor([-0.0976, -0.0510, -0.3727, -0.3994, -0.6439, -0.8401, -0.9132, -1.0761,\n",
       "         -1.3058, -1.1764, -1.5736, -1.5019, -1.8279, -1.7501, -2.2152, -2.1653,\n",
       "         -2.5494, -2.4089, -2.8760, -2.7074, -0.1883, -0.1615, -0.0973, -0.0857,\n",
       "         -0.0423], dtype=torch.float64),\n",
       " tensor([-0.0976, -0.0510, -0.3727, -0.3994, -0.6435, -0.8401, -0.9132, -1.0747,\n",
       "         -1.3053, -1.1753, -1.5720, -1.5019, -1.8255, -1.7501, -2.2141, -2.1652,\n",
       "         -2.5475, -2.4060, -2.8760, -2.7053, -0.1883, -0.1615, -0.0972, -0.0849,\n",
       "         -0.0423], dtype=torch.float64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle_1(train_x), oracle_01(train_x), oracle_001(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_x_all = torch.cat([train_x, train_x, train_x])\n",
    "train_y_all = torch.cat([oracle_1(train_x), oracle_01(train_x), oracle_001(train_x)])\n",
    "train_y_all = train_y_all.unsqueeze(-1)\n",
    "train_fid_all = torch.tensor([1]*len(train_x) + [2]*len(train_x) + [3]*len(train_x))\n",
    "train_fid_all = train_fid_all.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75, 7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = torch.cat([train_x_all, train_fid_all], axis=1)\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    }
   ],
   "source": [
    "from botorch.models.gp_regression_fidelity import SingleTaskMultiFidelityGP\n",
    "import gpytorch\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "\n",
    "fid_column = 6\n",
    "model = SingleTaskMultiFidelityGP(\n",
    "    train_input,\n",
    "    train_y_all,\n",
    "    outcome_transform=Standardize(m=1),\n",
    "    # fid column\n",
    "    data_fidelity=fid_column,\n",
    ")\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "mll.to(train_x)\n",
    "mll = fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.likelihood.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    posterior = model.posterior(torch.tensor([[0.0,0.0,0.0,0.0,0.0,0.0,1],[0.0,0.0,0.0,0.0,0.0,0.0,2],[0.0,0.0,0.0,0.0,0.0,0.0,3]]))\n",
    "    y_mean = posterior.mean\n",
    "    y_std = posterior.variance.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5702],\n",
       "         [-0.5702],\n",
       "         [-0.5702]], dtype=torch.float64),\n",
       " tensor([[0.8429],\n",
       "         [0.8429],\n",
       "         [0.8429]], dtype=torch.float64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_set, _, _ = dataset_handler.get_candidate_set(step=2, as_dataloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fid = torch.tensor([1]*len(plot_set)).unsqueeze(-1)\n",
    "test_input = torch.cat([plot_set[:], test_fid], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.likelihood.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    posterior = model.posterior(test_input)\n",
    "    y_mean = posterior.mean\n",
    "    y_std = posterior.variance.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5702],\n",
       "         [-0.6026],\n",
       "         [-0.6606],\n",
       "         ...,\n",
       "         [-0.7640],\n",
       "         [-0.5945],\n",
       "         [-0.5342]], dtype=torch.float64),\n",
       " tensor([[0.8429],\n",
       "         [0.8394],\n",
       "         [0.8346],\n",
       "         ...,\n",
       "         [0.7718],\n",
       "         [0.8178],\n",
       "         [0.8377]], dtype=torch.float64))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0011, 0.0010, 0.0007,  ..., 0.0001, 0.0007, 0.0012],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from botorch.acquisition.max_value_entropy_search import (\n",
    "    qLowerBoundMaxValueEntropy,\n",
    ")\n",
    "acqf = qLowerBoundMaxValueEntropy(\n",
    "    model,\n",
    "    candidate_set=test_input,\n",
    ")\n",
    "acqf(test_input.unsqueeze(1)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
