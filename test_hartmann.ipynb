{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  grid_size: 10\n",
      "  normalize_scores: true\n",
      "  train_fraction: 1.0\n",
      "  batch_size: 16384\n",
      "  shuffle: true\n",
      "  train_path: ~/activelearning/my_package/storage/hartmann/data_train.csv\n",
      "  test_path: null\n",
      "  _target_: activelearning.dataset.grid.HartmannDatasetHandler\n",
      "oracle:\n",
      "  _target_: activelearning.oracle.oracle.HartmannOracle\n",
      "  fidelity: 1\n",
      "  do_domain_map: true\n",
      "  negate: false\n",
      "sampler:\n",
      "  _target_: activelearning.sampler.sampler.GreedySampler\n",
      "  conf:\n",
      "    agent:\n",
      "      random_action_prob: 0.001\n",
      "      optimizer:\n",
      "        lr: 0.0005\n",
      "        n_train_steps: 5000\n",
      "    logger:\n",
      "      do:\n",
      "        online: true\n",
      "      project_name: test_hartmann_gflownet\n",
      "      run_name: identity_lr5e-4 newdata\n",
      "    env:\n",
      "      length: 10\n",
      "      n_dim: 6\n",
      "      cell_min: -1\n",
      "      cell_max: 1\n",
      "    proxy:\n",
      "      reward_func: power\n",
      "      reward_min: 1.0e-08\n",
      "      reward_function_kwargs:\n",
      "        beta: 1.0\n",
      "selector:\n",
      "  _target_: activelearning.selector.selector.Selector\n",
      "surrogate:\n",
      "  _target_: activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor\n",
      "acquisition:\n",
      "  _target_: activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition\n",
      "  acq_fn_class:\n",
      "    _target_: botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy\n",
      "    _partial_: true\n",
      "user:\n",
      "  logdir:\n",
      "    root: ./logs\n",
      "  data:\n",
      "    root: ./data\n",
      "logger:\n",
      "  _target_: activelearning.utils.logger.ConsoleLogger\n",
      "  project_name: test_hartmann\n",
      "  run_name: 10_greedy_gp_mve\n",
      "device: cpu\n",
      "float_precision: 32\n",
      "budget: 10\n",
      "n_samples: 5\n",
      "seed: 31415\n",
      "maximize: false\n",
      "\n",
      "{'dataset': {'grid_size': 10, 'normalize_scores': True, 'train_fraction': 1.0, 'batch_size': 16384, 'shuffle': True, 'train_path': '~/activelearning/my_package/storage/hartmann/data_train.csv', 'test_path': None, '_target_': 'activelearning.dataset.grid.HartmannDatasetHandler'}, 'oracle': {'_target_': 'activelearning.oracle.oracle.HartmannOracle', 'fidelity': 1, 'do_domain_map': True, 'negate': False}, 'sampler': {'_target_': 'activelearning.sampler.sampler.GreedySampler', 'conf': {'agent': {'random_action_prob': 0.001, 'optimizer': {'lr': 0.0005, 'n_train_steps': 5000}}, 'logger': {'do': {'online': True}, 'project_name': 'test_hartmann_gflownet', 'run_name': 'identity_lr5e-4 newdata'}, 'env': {'length': 10, 'n_dim': 6, 'cell_min': -1, 'cell_max': 1}, 'proxy': {'reward_func': 'power', 'reward_min': 1e-08, 'reward_function_kwargs': {'beta': 1.0}}}}, 'selector': {'_target_': 'activelearning.selector.selector.Selector'}, 'surrogate': {'_target_': 'activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor'}, 'acquisition': {'_target_': 'activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition', 'acq_fn_class': {'_target_': 'botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy', '_partial_': True}}, 'user': {'logdir': {'root': './logs'}, 'data': {'root': './data'}}, 'logger': {'_target_': 'activelearning.utils.logger.ConsoleLogger', 'project_name': 'test_hartmann', 'run_name': '10_greedy_gp_mve'}, 'device': 'cpu', 'float_precision': 32, 'budget': 10, 'n_samples': 5, 'seed': 31415, 'maximize': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'test_hartmann.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config = compose(config_name=\"test_hartmann.yaml\", overrides=[])\n",
    "    print(OmegaConf.to_yaml(config))\n",
    "    print(config)\n",
    "\n",
    "config.sampler.conf.logger.do.online = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = config.device\n",
    "n_iterations = config.budget  # TODO: replace with budget\n",
    "grid_size = config.env.length\n",
    "n_samples = config.n_samples\n",
    "\n",
    "from gflownet.utils.common import set_float_precision\n",
    "float_prec = config.float_precision\n",
    "# float_prec = set_float_precision(config.float_precision)\n",
    "\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "# colors = [\"red\", \"blue\", \"green\", \"orange\", \"brown\", \"pink\"]\n",
    "colors = plt.get_cmap(\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activelearning.dataset.grid import HartmannDatasetHandler\n",
    "from activelearning.utils.logger import WandBLogger, ConsoleLogger\n",
    "from activelearning.utils.plotter import ProjectionPlotHelper\n",
    "from gflownet.envs.grid import Grid as GridEnv\n",
    "from functools import partial\n",
    "\n",
    "# Environment\n",
    "env_maker = partial(GridEnv, n_dim=6, length=grid_size)\n",
    "\n",
    "# Dataset\n",
    "dataset_handler = HartmannDatasetHandler(\n",
    "    env=env_maker(),\n",
    "    train_path=\"./data/hartmann/data_train.csv\",\n",
    "    train_fraction=1.0,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "candidate_set, xi, yi = dataset_handler.get_candidate_set(step=1, as_dataloader=True)\n",
    "plot_set, _, _ = dataset_handler.get_candidate_set(step=2, as_dataloader=False)\n",
    "\n",
    "# logger = WandBLogger(project_name=\"test_hartmann_plots\", run_name=\"GreedySampler\")\n",
    "# logger = None\n",
    "logger = ConsoleLogger(project_name=\"test_hartmann\", run_name=\"Greedy 10\")\n",
    "\n",
    "# plotter = None\n",
    "# plotter = ProjectionPlotHelper(plot_set[:])\n",
    "plotter = ProjectionPlotHelper(plot_set[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: tensor(0.0425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: tensor(0.0425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    }
   ],
   "source": [
    "from activelearning.surrogate.gp_surrogate import SingleTaskGPRegressor\n",
    "from activelearning.acquisition.acquisition import BOTorchMaxValueEntropyAcquisition\n",
    "from activelearning.sampler.sampler import GreedySampler, RandomSampler\n",
    "from activelearning.selector.selector import Selector, ScoreSelector\n",
    "from activelearning.oracle.oracle import HartmannOracle\n",
    "\n",
    "# Oracle\n",
    "oracle = HartmannOracle(fidelity=1, device=device, float_precision=float_prec)\n",
    "\n",
    "if plotter is not None:\n",
    "    fig_oracle, ax_oracle = plotter.plot_function(oracle)\n",
    "\n",
    "\n",
    "best_scores = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    train_data, test_data = dataset_handler.get_dataloader()\n",
    "    # print(\"iteration\", i)\n",
    "    # Surrogate (e.g., Bayesian Optimization)\n",
    "    # starts with a clean slate each iteration\n",
    "    surrogate = SingleTaskGPRegressor(\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "    )\n",
    "    surrogate.fit(train_data)\n",
    "\n",
    "    acq_fn = BOTorchMaxValueEntropyAcquisition(\n",
    "        surrogate.model,\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "    )\n",
    "\n",
    "    # Sampler (e.g., GFlowNet, or Random Sampler)\n",
    "    # also starts with a clean slate; TODO: experiment with NOT training from scratch\n",
    "    # sampler = RandomSampler(\n",
    "    #     acq_fn,\n",
    "    # )\n",
    "    sampler = GreedySampler(\n",
    "        acquisition=acq_fn,\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "    )\n",
    "    # sampler = hydra.utils.instantiate(\n",
    "    #     config.sampler,\n",
    "    #     env_maker=env_maker,\n",
    "    #     acquisition=acq_fn,\n",
    "    #     device=device,\n",
    "    #     float_precision=float_prec,\n",
    "    #     _recursive_=False,\n",
    "    # )\n",
    "\n",
    "    sampler.fit()  # only necessary for samplers that train a model\n",
    "\n",
    "    samples, _ = sampler.get_samples(n_samples * 5, candidate_set=candidate_set)\n",
    "\n",
    "    if plotter is not None and hasattr(sampler, \"sampler\"):\n",
    "\n",
    "        def reward_fn(samples):\n",
    "            return sampler.sampler.proxy.proxy2reward(sampler.sampler.proxy(samples))\n",
    "\n",
    "        fig_reward, ax_reward = plotter.plot_function(reward_fn)\n",
    "        fig_reward, ax_reward = plotter.plot_samples(samples, ax_reward, fig_reward)\n",
    "        ax_reward.set_title(\"reward fn + proposed samples of iteration %i\" % i)\n",
    "        logger.log_figure(fig_reward, \"reward\")\n",
    "\n",
    "    # Selector\n",
    "    # selector = Selector()\n",
    "    selector = ScoreSelector(\n",
    "        acq_fn,\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "        maximize=True,\n",
    "    )\n",
    "    filtered_samples, _ = selector(n_samples=n_samples, candidate_set=samples.clone())\n",
    "\n",
    "    if plotter is not None:\n",
    "        fig_acq, ax_acq = plotter.plot_function(acq_fn)\n",
    "        fig_acq, ax_acq = plotter.plot_samples(filtered_samples, ax_acq, fig_acq)\n",
    "        ax_acq.set_title(\"acquisition fn + selected samples of iteration %i\" % i)\n",
    "        logger.log_figure(fig_acq, \"acq\")\n",
    "\n",
    "    if plotter is not None:\n",
    "        fig_acq, ax_acq = plotter.plot_samples(\n",
    "            filtered_samples,\n",
    "            ax_oracle,\n",
    "            fig_oracle,\n",
    "            c=cm.to_hex(colors(i / n_iterations)),\n",
    "            label=\"it %i\" % i,\n",
    "        )\n",
    "\n",
    "    del surrogate\n",
    "    del sampler\n",
    "    del selector\n",
    "\n",
    "    scores = oracle(filtered_samples.clone())\n",
    "    scores = dataset_handler.update_dataset(filtered_samples.cpu(), scores.cpu())\n",
    "    best_scores.append(scores.max().cpu())\n",
    "    if logger is not None:\n",
    "        logger.log_metric(scores.max().cpu(), \"best_score\")\n",
    "\n",
    "if plotter is not None:\n",
    "    fig_oracle.legend()\n",
    "    ax_oracle.set_title(\"oracle fn + samples\")\n",
    "    logger.log_figure(fig_oracle, key=\"oracle\")\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(best_scores)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"scores\")\n",
    "plt.title(\"Best Score in each iteration\")\n",
    "if logger is not None:\n",
    "    logger.log_figure(fig, key=\"best_scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activelearning.dataset.grid import HartmannDatasetHandler\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset_handler = HartmannDatasetHandler(\n",
    "    grid_size=10,\n",
    "    train_path=\"./data/hartmann/data_train.csv\",\n",
    "    train_fraction=1.0,\n",
    "    float_precision=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activelearning.oracle.oracle import HartmannOracle\n",
    "oracle = HartmannOracle(fidelity=1, device=\"cpu\", float_precision=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4000, -0.2000, -0.8000,  0.8000, -1.0000, -0.6000],\n",
       "        [-0.2000, -0.6000, -1.0000,  0.2000,  0.6000, -0.6000],\n",
       "        [ 0.4000, -0.6000, -1.0000, -0.2000,  0.0000,  0.8000],\n",
       "        [ 0.0000,  0.2000, -0.8000, -1.0000, -0.4000,  0.6000],\n",
       "        [-0.6000,  0.2000,  0.0000, -0.2000, -0.6000, -0.6000],\n",
       "        [-0.4000,  0.6000,  0.6000,  0.8000,  0.0000, -1.0000],\n",
       "        [ 0.6000, -0.4000, -0.4000, -0.4000, -0.4000,  0.6000],\n",
       "        [-0.4000, -0.8000,  0.2000, -0.2000, -0.8000,  0.0000],\n",
       "        [-0.6000, -1.0000,  0.8000, -0.6000, -0.6000,  0.2000],\n",
       "        [-0.6000, -0.2000, -0.4000, -0.4000,  0.0000,  0.6000],\n",
       "        [-0.6000, -0.4000,  0.2000,  0.0000, -0.6000,  0.4000],\n",
       "        [ 0.0000,  0.6000,  0.8000,  0.4000,  0.2000, -0.6000],\n",
       "        [-0.4000, -0.2000,  0.2000, -0.2000, -0.2000,  0.2000],\n",
       "        [ 0.0000,  0.6000, -0.6000, -0.2000,  0.6000, -1.0000],\n",
       "        [ 0.0000, -0.8000,  0.2000, -0.4000, -0.4000,  0.2000],\n",
       "        [-0.2000,  0.8000, -0.2000, -0.2000,  0.2000, -0.8000],\n",
       "        [-0.4000, -0.4000,  0.4000, -0.4000, -0.4000,  0.4000],\n",
       "        [-1.0000, -1.0000,  0.2000, -0.4000, -0.4000,  0.4000],\n",
       "        [-0.2000,  0.6000,  0.4000,  0.2000,  0.2000, -1.0000],\n",
       "        [-0.4000, -0.6000,  0.0000, -0.2000, -0.4000,  0.4000],\n",
       "        [-0.4000, -1.0000,  0.6000,  0.6000, -0.8000,  0.6000],\n",
       "        [ 0.6000,  0.6000, -0.2000,  0.0000, -0.4000,  0.2000],\n",
       "        [-0.6000, -0.4000,  0.8000,  0.4000,  0.0000, -0.4000],\n",
       "        [-0.6000, -1.0000, -0.6000, -0.6000,  0.8000,  0.2000],\n",
       "        [-0.2000, -0.2000, -1.0000,  0.8000, -0.4000,  0.4000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset_handler.train_data[:]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.9138e-12, 6.3033e-09, 2.9070e-04, 3.4004e-12, 8.1035e-12, 8.0648e-12,\n",
       "        4.9619e-07, 2.3959e-07, 7.2198e-08, 1.6322e-04, 4.8693e-06, 2.5948e-04,\n",
       "        3.1359e-04, 6.5036e-11, 7.2960e-05, 1.3655e-09, 4.7255e-04, 4.9290e-10,\n",
       "        4.7440e-10, 3.7299e-06, 3.1314e-06, 2.0790e-02, 1.9947e-06, 8.2647e-10,\n",
       "        4.9141e-07])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3224)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.get_max_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet.envs.grid import Grid as GridEnv\n",
    "from activelearning.dataset.grid import HartmannDatasetHandler\n",
    "env = GridEnv(n_dim=6, length=10)\n",
    "dataset_handler = HartmannDatasetHandler(\n",
    "    env=env,\n",
    "    train_path=\"./data/hartmann/data_train.csv\",\n",
    "    train_fraction=1.0,\n",
    "    float_precision=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_set, xi, yi = dataset_handler.get_candidate_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4., 1., 9., 0., 2.],\n",
      "        [4., 2., 0., 6., 8., 2.],\n",
      "        [7., 2., 0., 4., 5., 9.],\n",
      "        [5., 6., 1., 0., 3., 8.],\n",
      "        [2., 6., 5., 4., 2., 2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3333, -0.1111, -0.7778,  1.0000, -1.0000, -0.5556],\n",
       "         [-0.1111, -0.5556, -1.0000,  0.3333,  0.7778, -0.5556],\n",
       "         [ 0.5556, -0.5556, -1.0000, -0.1111,  0.1111,  1.0000],\n",
       "         [ 0.1111,  0.3333, -0.7778, -1.0000, -0.3333,  0.7778],\n",
       "         [-0.5556,  0.3333,  0.1111, -0.1111, -0.5556, -0.5556]]),\n",
       " tensor([1.6899e-10, 3.0302e-07, 1.3983e-02, 0.0000e+00, 2.2622e-10]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_handler.train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7778],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5556],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.1111]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.tensor([[0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 1.],\n",
    "        [0., 0., 0., 0., 0., 2.],\n",
    "        [0., 0., 0., 0., 0., 3.],\n",
    "        [0., 0., 0., 0., 0., 4.]], dtype=torch.float64)\n",
    "env.states2proxy(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 2.],\n",
      "        [0., 0., 0., 0., 0., 3.],\n",
      "        [0., 0., 0., 0., 0., 4.]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [6], [30]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcandidate_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/activelearning/activelearning/dataset/dataset.py:32\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     y_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_data[index]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m---> 32\u001b[0m x_set, y_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_set\n",
      "File \u001b[0;32m~/activelearning/activelearning/dataset/grid.py:64\u001b[0m, in \u001b[0;36mGridData.preprocess\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(states)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate2result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate2result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_scores \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/al_new/lib/python3.10/site-packages/gflownet/envs/base.py:688\u001b[0m, in \u001b[0;36mGFlowNetEnv.state2proxy\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03mPrepares a single state in \"GFlowNet format\" for the proxy. By default, simply\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03mstates2proxy is called and the output will be a \"batch\" with a single state in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m    A state\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    687\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_state(state)\n\u001b[0;32m--> 688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates2proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/al_new/lib/python3.10/site-packages/gflownet/envs/grid.py:147\u001b[0m, in \u001b[0;36mGrid.states2proxy\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mPrepares a batch of states in \"environment format\" for the proxy: each state is\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03ma vector of length n_dim with values in the range [cell_min, cell_max].\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03mA tensor containing all the states in the batch.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m states \u001b[38;5;241m=\u001b[39m tfloat(states, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, float_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates2policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    148\u001b[0m         (states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength)\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcells[\u001b[38;5;28;01mNone\u001b[39;00m, :])\u001b[38;5;241m.\u001b[39mto(states\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    151\u001b[0m )\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/al_new/lib/python3.10/site-packages/gflownet/envs/grid.py:186\u001b[0m, in \u001b[0;36mGrid.states2policy\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m    182\u001b[0m rows \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(torch\u001b[38;5;241m.\u001b[39marange(n_states), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dim)\n\u001b[1;32m    183\u001b[0m states_policy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    184\u001b[0m     (n_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dim), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    185\u001b[0m )\n\u001b[0;32m--> 186\u001b[0m \u001b[43mstates_policy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m states_policy\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [6], [30]"
     ]
    }
   ],
   "source": [
    "candidate_set.dataset[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
