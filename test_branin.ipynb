{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Hydra Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 'cpu', 'float_precision': 32, 'budget': 5, 'n_samples': 3, 'seed': 31415, 'maximize': False, 'dataset': {'grid_size': 10, 'normalize_scores': True, 'train_fraction': 1.0, 'batch_size': 16, 'shuffle': True, 'train_path': '${user.data.root}/branin/data_10_train.csv', 'test_path': None, '_target_': 'activelearning.dataset.grid.BraninDatasetHandler'}, 'oracle': {'_target_': 'activelearning.oracle.oracle.BraninOracle', 'fidelity': 1, 'do_domain_map': True}, 'selector': {'_target_': 'activelearning.selector.selector.Selector'}, 'sampler': {'_target_': 'activelearning.sampler.sampler.GreedySampler'}, 'surrogate': {'_target_': 'activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor'}, 'acquisition': {'_target_': 'activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition', 'acq_fn_class': {'_target_': 'botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy', '_partial_': True}}, 'user': {'logdir': {'root': './logs'}, 'data': {'root': './data'}}, 'logger': {'_target_': 'activelearning.utils.logger.ConsoleLogger', 'project_name': 'activelearning', 'run_name': None}}\n"
     ]
    }
   ],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config = compose(config_name=\"main.yaml\", overrides=[])\n",
    "    # print(OmegaConf.to_yaml(env_config))\n",
    "    print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': 'cpu', 'float_precision': 32, 'budget': 5, 'n_samples': 3, 'seed': 31415, 'maximize': False, 'dataset': {'grid_size': 10, 'normalize_scores': True, 'train_fraction': 1.0, 'batch_size': 16, 'shuffle': True, 'train_path': '${user.data.root}/branin/data_10_train.csv', 'test_path': None, '_target_': 'activelearning.dataset.grid.BraninDatasetHandler'}, 'oracle': {'_target_': 'activelearning.oracle.oracle.Branin', 'fidelity': 1, 'do_domain_map': True}, 'selector': {'_target_': 'activelearning.selector.selector.Selector'}, 'sampler': {'_target_': 'activelearning.sampler.sampler.GreedySampler'}, 'surrogate': {'_target_': 'activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor'}, 'acquisition': {'_target_': 'activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition', 'acq_fn_class': {'_target_': 'botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy', '_partial_': True}}, 'user': {'logdir': {'root': './logs'}, 'data': {'root': './data'}}, 'logger': {'_target_': 'activelearning.utils.logger_activelearning.ActiveLearningLogger', 'do': {'online': False, 'times': False}, 'ckpts': {'policy': {'period': 5000}, 'regressor': {'period': 10}}, 'train': {'period': 1}, 'test': {'first_it': True, 'period': 100, 'n': 100, 'kde': {'bandwidth': 0.1, 'kernel': 'gaussian'}}, 'oracle': {'period': 100000, 'k': [1, 10, 100]}, 'logdir': {'root': './logs', 'ckpts': 'ckpts', 'data': 'data', 'overwrite': True}, 'lightweight': False, 'progress': True, 'debug': False, 'project_name': 'activelearning', 'tags': ['dummy1', 'dummy2']}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = hydra.utils.instantiate(\n",
    "    config.dataset,\n",
    "    float_precision=config.float_precision,\n",
    ")\n",
    "\n",
    "oracle = hydra.utils.instantiate(\n",
    "    config.oracle,\n",
    "    device=config.device,\n",
    "    float_precision=config.float_precision,\n",
    ")\n",
    "\n",
    "surrogate = hydra.utils.instantiate(\n",
    "    config.surrogate,\n",
    "    device=config.device,\n",
    "    float_precision=config.float_precision,\n",
    ")\n",
    "\n",
    "acquisition = hydra.utils.instantiate(\n",
    "    config.acquisition,\n",
    "    surrogate_model=surrogate,\n",
    "    dataset_handler=dataset,\n",
    "    device=config.device,\n",
    "    float_precision=config.float_precision,\n",
    ")\n",
    "\n",
    "sampler = hydra.utils.instantiate(\n",
    "    config.sampler,\n",
    "    acquisition=acquisition,\n",
    "    device=config.device,\n",
    "    float_precision=config.float_precision,\n",
    ")\n",
    "\n",
    "selector = hydra.utils.instantiate(\n",
    "    config.selector,\n",
    "    score_fn=acquisition.get_acquisition_values,\n",
    "    device=config.device,\n",
    "    float_precision=config.float_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Larger Branin Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activelearning.dataset.grid import BraninDatasetHandler\n",
    "from activelearning.oracle.oracle import BraninOracle\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset_handler = BraninDatasetHandler(\n",
    "    grid_size=100,\n",
    "    train_path=\"./data/branin/data_%i_train.csv\" % 100,\n",
    "    train_fraction=1.0,\n",
    "    float_precision=32,\n",
    ")\n",
    "\n",
    "candidate_set, xi, yi = dataset_handler.get_candidate_set()\n",
    "\n",
    "# Oracle\n",
    "oracle = BraninOracle(\n",
    "    fidelity=1, do_domain_map=True, device=\"cpu\", float_precision=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f710c53d630>, None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniform sampling\n",
    "import numpy as np\n",
    "subset_idcs = np.random.uniform(0,1,size=(len(candidate_set)))>0.97\n",
    "subset = candidate_set[subset_idcs]\n",
    "from activelearning.oracle.oracle import BraninOracle\n",
    "oracle = BraninOracle(fidelity=1, device=\"cpu\", float_precision=32)\n",
    "\n",
    "dataset_handler.update_dataset(subset, oracle(subset.clone()), \"data/branin/large_branin_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([74, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quadrant sampling\n",
    "import numpy as np\n",
    "candidate_q1 = candidate_set[(candidate_set[:,0]<0.5) * (candidate_set[:,1]<0.5)]\n",
    "candidate_q2 = candidate_set[(candidate_set[:,0]<0.5) * (candidate_set[:,1]>=0.5)]\n",
    "candidate_q3 = candidate_set[(candidate_set[:,0]>=0.5) * (candidate_set[:,1]<0.5)]\n",
    "candidate_q4 = candidate_set[(candidate_set[:,0]>=0.5) * (candidate_set[:,1]>=0.5)]\n",
    "\n",
    "subset_idcs_1 = np.random.uniform(0,1,size=(len(candidate_q1)))>0.99\n",
    "subset_idcs_2 = np.random.uniform(0,1,size=(len(candidate_q1)))>0.99\n",
    "subset_idcs_3 = np.random.uniform(0,1,size=(len(candidate_q1)))>0.99\n",
    "subset_idcs_4 = np.random.uniform(0,1,size=(len(candidate_q1)))>1.0\n",
    "\n",
    "subset_1 = candidate_q1[subset_idcs_1]\n",
    "subset_2 = candidate_q2[subset_idcs_2]\n",
    "subset_3 = candidate_q3[subset_idcs_3]\n",
    "subset_4 = candidate_q4[subset_idcs_4]\n",
    "\n",
    "import torch\n",
    "subset = torch.concat([subset_1, subset_2, subset_3, subset_4])\n",
    "subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f8dd0bdd0f0>, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from activelearning.oracle.oracle import BraninOracle\n",
    "oracle = BraninOracle(fidelity=1, device=\"cpu\", float_precision=32)\n",
    "\n",
    "dataset_handler.update_dataset(subset, oracle(subset.clone()), \"data/branin/large_branin_quadrant_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'test_branin.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  train_fraction: 1.0\n",
      "  batch_size: 16\n",
      "  shuffle: true\n",
      "  train_path: ~/activelearning/data/branin/data_100_train.csv\n",
      "  test_path: null\n",
      "  _target_: activelearning.dataset.grid.BraninDatasetHandler\n",
      "env:\n",
      "  _target_: gflownet.envs.grid.Grid\n",
      "  env_id: env\n",
      "  fixed_distr_params: null\n",
      "  random_distr_params: null\n",
      "  skip_mask_check: false\n",
      "  conditional: false\n",
      "  continuous: false\n",
      "  id: grid\n",
      "  func: corners\n",
      "  n_dim: 2\n",
      "  length: 100\n",
      "  max_increment: 1\n",
      "  max_dim_per_action: 1\n",
      "  cell_min: -1\n",
      "  cell_max: 1\n",
      "  buffer:\n",
      "    train: null\n",
      "    test: null\n",
      "oracle:\n",
      "  _target_: activelearning.oracle.oracle.BraninOracle\n",
      "  fidelity: 1\n",
      "  do_domain_map: true\n",
      "  negate: false\n",
      "sampler:\n",
      "  conf:\n",
      "    policy:\n",
      "      forward:\n",
      "        _target_: gflownet.policy.base.Policy\n",
      "        config:\n",
      "          type: mlp\n",
      "          n_hid: 2048\n",
      "          n_layers: 2\n",
      "          checkpoint: null\n",
      "          reload_ckpt: false\n",
      "          is_model: false\n",
      "      backward:\n",
      "        _target_: gflownet.policy.base.Policy\n",
      "        config: null\n",
      "      shared: null\n",
      "    agent:\n",
      "      _target_: gflownet.gflownet.GFlowNetAgent\n",
      "      seed: 0\n",
      "      optimizer:\n",
      "        loss: trajectorybalance\n",
      "        lr: 0.0005\n",
      "        lr_decay_period: 1000000\n",
      "        lr_decay_gamma: 0.5\n",
      "        z_dim: 16\n",
      "        lr_z_mult: 100\n",
      "        method: adam\n",
      "        early_stopping: 0.0\n",
      "        ema_alpha: 0.5\n",
      "        adam_beta1: 0.9\n",
      "        adam_beta2: 0.999\n",
      "        sgd_momentum: 0.9\n",
      "        batch_size:\n",
      "          forward: 10\n",
      "          backward_dataset: 0\n",
      "          backward_replay: 0\n",
      "        train_to_sample_ratio: 1\n",
      "        n_train_steps: 500\n",
      "        bootstrap_tau: 0.0\n",
      "        clip_grad_norm: 0.0\n",
      "      state_flow: null\n",
      "      batch_reward: true\n",
      "      mask_invalid_actions: true\n",
      "      temperature_logits: 1.0\n",
      "      random_action_prob: 0.0\n",
      "      pct_offline: 0.0\n",
      "      replay_capacity: 0\n",
      "      replay_sampling: permutation\n",
      "      train_sampling: permutation\n",
      "      num_empirical_loss: 200000\n",
      "      use_context: false\n",
      "      evaluator:\n",
      "        _target_: gflownet.evaluator.base.BaseEvaluator\n",
      "        first_it: true\n",
      "        period: 100\n",
      "        'n': 100\n",
      "        kde:\n",
      "          bandwidth: 0.1\n",
      "          kernel: gaussian\n",
      "        n_top_k: 5000\n",
      "        top_k: 100\n",
      "        top_k_period: -1\n",
      "        n_trajs_logprobs: 10\n",
      "        logprobs_batch_size: 100\n",
      "        logprobs_bootstrap_size: 10000\n",
      "        max_data_logprobs: 100000.0\n",
      "        n_grid: 40000\n",
      "        train_log_period: 1\n",
      "        checkpoints_period: 1000\n",
      "        metrics: all\n",
      "      buffer:\n",
      "        replay_capacity: 0\n",
      "        train: null\n",
      "        test: null\n",
      "    logger:\n",
      "      _target_: gflownet.utils.logger.Logger\n",
      "      do:\n",
      "        online: false\n",
      "        times: false\n",
      "      project_name: test_gflownet\n",
      "      logdir:\n",
      "        root: activelearning/gflownet/logs\n",
      "        ckpts: activelearning/gflownetckpts\n",
      "        overwrite: true\n",
      "      debug: false\n",
      "      lightweight: false\n",
      "      progress: true\n",
      "      context: '0'\n",
      "      notes: null\n",
      "      tags:\n",
      "      - gflownet\n",
      "      run_name: identity_lr5e-4\n",
      "    proxy:\n",
      "      _target_: activelearning.sampler.proxy.AcquisitionProxy\n",
      "      reward_function: power\n",
      "      logreward_function: null\n",
      "      reward_function_kwargs:\n",
      "        beta: 1.0\n",
      "      reward_min: 1.0e-08\n",
      "      do_clip_rewards: false\n",
      "    state_flow: null\n",
      "  _target_: activelearning.sampler.sampler.GFlowNetSampler\n",
      "selector:\n",
      "  _target_: activelearning.selector.selector.ScoreSelector\n",
      "surrogate:\n",
      "  _target_: activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor\n",
      "acquisition:\n",
      "  _target_: activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition\n",
      "  acq_fn_class:\n",
      "    _target_: botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy\n",
      "    _partial_: true\n",
      "user:\n",
      "  logdir:\n",
      "    root: ./logs\n",
      "  data:\n",
      "    root: ./data\n",
      "logger:\n",
      "  _target_: activelearning.utils.logger.WandBLogger\n",
      "  project_name: test_branin\n",
      "  run_name: ${env.length}_random_gp_mve\n",
      "device: cpu\n",
      "float_precision: 32\n",
      "budget: 10\n",
      "n_samples: 5\n",
      "seed: 31415\n",
      "maximize: false\n",
      "\n",
      "{'dataset': {'train_fraction': 1.0, 'batch_size': 16, 'shuffle': True, 'train_path': '~/activelearning/data/branin/data_100_train.csv', 'test_path': None, '_target_': 'activelearning.dataset.grid.BraninDatasetHandler'}, 'env': {'_target_': 'gflownet.envs.grid.Grid', 'env_id': 'env', 'fixed_distr_params': None, 'random_distr_params': None, 'skip_mask_check': False, 'conditional': False, 'continuous': False, 'id': 'grid', 'func': 'corners', 'n_dim': 2, 'length': 100, 'max_increment': 1, 'max_dim_per_action': 1, 'cell_min': -1, 'cell_max': 1, 'buffer': {'train': None, 'test': None}}, 'oracle': {'_target_': 'activelearning.oracle.oracle.BraninOracle', 'fidelity': 1, 'do_domain_map': True, 'negate': False}, 'sampler': {'conf': {'policy': {'forward': {'_target_': 'gflownet.policy.base.Policy', 'config': {'type': 'mlp', 'n_hid': 2048, 'n_layers': 2, 'checkpoint': None, 'reload_ckpt': False, 'is_model': False}}, 'backward': {'_target_': 'gflownet.policy.base.Policy', 'config': None}, 'shared': None}, 'agent': {'_target_': 'gflownet.gflownet.GFlowNetAgent', 'seed': 0, 'optimizer': {'loss': 'trajectorybalance', 'lr': 0.0005, 'lr_decay_period': 1000000, 'lr_decay_gamma': 0.5, 'z_dim': 16, 'lr_z_mult': 100, 'method': 'adam', 'early_stopping': 0.0, 'ema_alpha': 0.5, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'sgd_momentum': 0.9, 'batch_size': {'forward': 10, 'backward_dataset': 0, 'backward_replay': 0}, 'train_to_sample_ratio': 1, 'n_train_steps': 500, 'bootstrap_tau': 0.0, 'clip_grad_norm': 0.0}, 'state_flow': None, 'batch_reward': True, 'mask_invalid_actions': True, 'temperature_logits': 1.0, 'random_action_prob': 0.0, 'pct_offline': 0.0, 'replay_capacity': 0, 'replay_sampling': 'permutation', 'train_sampling': 'permutation', 'num_empirical_loss': 200000, 'use_context': False, 'evaluator': {'_target_': 'gflownet.evaluator.base.BaseEvaluator', 'first_it': True, 'period': 100, 'n': 100, 'kde': {'bandwidth': 0.1, 'kernel': 'gaussian'}, 'n_top_k': 5000, 'top_k': 100, 'top_k_period': -1, 'n_trajs_logprobs': 10, 'logprobs_batch_size': 100, 'logprobs_bootstrap_size': 10000, 'max_data_logprobs': 100000.0, 'n_grid': 40000, 'train_log_period': 1, 'checkpoints_period': 1000, 'metrics': 'all'}, 'buffer': {'replay_capacity': 0, 'train': None, 'test': None}}, 'logger': {'_target_': 'gflownet.utils.logger.Logger', 'do': {'online': False, 'times': False}, 'project_name': 'test_gflownet', 'logdir': {'root': 'activelearning/gflownet/logs', 'ckpts': 'activelearning/gflownetckpts', 'overwrite': True}, 'debug': False, 'lightweight': False, 'progress': True, 'context': '0', 'notes': None, 'tags': ['gflownet'], 'run_name': 'identity_lr5e-4'}, 'proxy': {'_target_': 'activelearning.sampler.proxy.AcquisitionProxy', 'reward_function': 'power', 'logreward_function': None, 'reward_function_kwargs': {'beta': 1.0}, 'reward_min': 1e-08, 'do_clip_rewards': False}, 'state_flow': None}, '_target_': 'activelearning.sampler.sampler.GFlowNetSampler'}, 'selector': {'_target_': 'activelearning.selector.selector.ScoreSelector'}, 'surrogate': {'_target_': 'activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor'}, 'acquisition': {'_target_': 'activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition', 'acq_fn_class': {'_target_': 'botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy', '_partial_': True}}, 'user': {'logdir': {'root': './logs'}, 'data': {'root': './data'}}, 'logger': {'_target_': 'activelearning.utils.logger.WandBLogger', 'project_name': 'test_branin', 'run_name': '${env.length}_random_gp_mve'}, 'device': 'cpu', 'float_precision': 32, 'budget': 10, 'n_samples': 5, 'seed': 31415, 'maximize': False}\n"
     ]
    }
   ],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config = compose(config_name=\"test_branin.yaml\", overrides=[])\n",
    "    print(OmegaConf.to_yaml(config))\n",
    "    print(config)\n",
    "\n",
    "config.sampler.conf.logger.do.online = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = config.device\n",
    "n_iterations = config.budget  # TODO: replace with budget\n",
    "grid_size = config.env.length\n",
    "n_samples = config.n_samples\n",
    "\n",
    "from gflownet.utils.common import set_float_precision\n",
    "float_prec = set_float_precision(config.float_precision)\n",
    "# float_prec = set_float_precision(32)\n",
    "\n",
    "import matplotlib.colors as cm\n",
    "import matplotlib.pyplot as plt\n",
    "# colors = [\"red\", \"blue\", \"green\", \"orange\", \"brown\", \"pink\"]\n",
    "colors = plt.get_cmap(\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Important: offline trajectories will NOT be sampled. In order to sample\n",
      "            offline trajectories, the train configuration of the buffer should be\n",
      "            complete and feasible. It should at least specify env.buffer.train.type.\n",
      "            \n",
      "\n",
      "            Important: test metrics will NOT be computed. In order to compute\n",
      "            test metrics the test configuration of the buffer should be complete and\n",
      "            feasible. It should at least specify env.buffer.test.type.\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/mila/c/christina.humer/gflownet-dev/gflownet/utils/buffer.py:141: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.main = pd.concat(\n",
      "Loss: 1.6406 | Mean rewards: 0.12 | JSD: -1.0000:  85%|████████▌ | 425/500 [03:38<00:56,  1.33it/s]  "
     ]
    }
   ],
   "source": [
    "from activelearning.dataset.grid import BraninDatasetHandler\n",
    "from activelearning.surrogate.gp_surrogate import (\n",
    "    SingleTaskGPRegressor,\n",
    "    DeepKernelSVGPSurrogate,\n",
    ")\n",
    "from activelearning.acquisition.acquisition import BOTorchMaxValueEntropyAcquisition\n",
    "from activelearning.sampler.sampler import GreedySampler, RandomSampler\n",
    "from activelearning.selector.selector import Selector, ScoreSelector\n",
    "from activelearning.oracle.oracle import BraninOracle\n",
    "from activelearning.surrogate.feature_extractor.mlp import MLP, Identity\n",
    "from gflownet.envs.grid import Grid as GridEnv\n",
    "from functools import partial\n",
    "\n",
    "# Environment\n",
    "env_maker = partial(GridEnv, n_dim=2, length=grid_size)\n",
    "\n",
    "# Dataset\n",
    "dataset_handler = BraninDatasetHandler(\n",
    "    env=env_maker(),\n",
    "    train_path=\"./data/branin/data_%i_train.csv\" % grid_size,\n",
    "    train_fraction=1.0,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "\n",
    "candidate_set, xi, yi = dataset_handler.get_candidate_set()\n",
    "\n",
    "from activelearning.utils.logger import WandBLogger, ConsoleLogger\n",
    "\n",
    "# logger = WandBLogger(project_name=\"test_branin\", run_name=\"100_greedy_gp_mve_fix-selector\") # \"100_continuous-gflownet_gp_mve\" # \"100_greedy_dkl-30epochs_mve\"\n",
    "logger = ConsoleLogger(project_name=\"test_branin\", run_name=\"Greedy 10x10\")\n",
    "# logger = None\n",
    "\n",
    "\n",
    "from activelearning.utils.plotter import PlotHelper, BraninCIME4RExportHelper\n",
    "\n",
    "plotter = PlotHelper()\n",
    "# plotter = BraninCIME4RExportHelper(dataset_handler)\n",
    "\n",
    "# Oracle\n",
    "oracle = BraninOracle(\n",
    "    fidelity=1, do_domain_map=True, device=device, float_precision=float_prec\n",
    ")\n",
    "\n",
    "if plotter is not None:\n",
    "    fig_oracle, ax_oracle = plotter.plot_function(\n",
    "        oracle, candidate_set[:], xi=xi, yi=yi, label=\"oraclefn\"\n",
    "    )\n",
    "\n",
    "\n",
    "best_scores = []\n",
    "all_scores = {}\n",
    "\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    train_data, test_data = dataset_handler.get_dataloader()\n",
    "    # print(\"iteration\", i)\n",
    "    # Surrogate (e.g., Bayesian Optimization)\n",
    "    # starts with a clean slate each iteration\n",
    "    surrogate = SingleTaskGPRegressor(\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "    )\n",
    "\n",
    "    # feature_extractor = Identity(2)\n",
    "    # feature_extractor = MLP(\n",
    "    #     n_input=2,\n",
    "    #     n_hidden=[16, 16],\n",
    "    #     n_output=7,\n",
    "    #     float_precision=32,\n",
    "    # )\n",
    "    # surrogate = DeepKernelSVGPSurrogate(\n",
    "    #     feature_extractor,\n",
    "    #     float_precision=float_prec,\n",
    "    #     device=device,\n",
    "    #     mll_args={\"num_data\": len(train_data.dataset)},\n",
    "    #     train_epochs=30,\n",
    "    #     lr=0.1,\n",
    "    #     logger=logger,\n",
    "    # )\n",
    "    surrogate.fit(train_data)\n",
    "\n",
    "    acq_fn = BOTorchMaxValueEntropyAcquisition(\n",
    "        surrogate.model, device=device, float_precision=float_prec\n",
    "    )\n",
    "\n",
    "    # Sampler (e.g., GFlowNet, or Random Sampler)\n",
    "    # also starts with a clean slate; TODO: experiment with NOT training from scratch\n",
    "    # sampler = RandomSampler(acq_fn)\n",
    "    # sampler = GreedySampler(\n",
    "    #     acq_fn,\n",
    "    #     device=device,\n",
    "    #     float_precision=float_prec,\n",
    "    # )\n",
    "    sampler = hydra.utils.instantiate(\n",
    "        config.sampler,\n",
    "        env_maker=env_maker,\n",
    "        acquisition=acq_fn,\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "        _recursive_=False,\n",
    "    )\n",
    "\n",
    "    sampler.fit()  # only necessary for samplers that train a model\n",
    "\n",
    "    samples, sample_idcs = sampler.get_samples(\n",
    "        n_samples * 5, candidate_set=candidate_set\n",
    "    )\n",
    "\n",
    "    if plotter is not None and hasattr(sampler, \"sampler\"):\n",
    "\n",
    "        def reward_fn(samples):\n",
    "            return sampler.sampler.proxy.proxy2reward(sampler.sampler.proxy(samples))\n",
    "\n",
    "        fig_reward, ax_reward = plotter.plot_function(\n",
    "            reward_fn,\n",
    "            candidate_set[:],\n",
    "            xi=xi,\n",
    "            yi=yi,\n",
    "            label=\"rewardfn\",\n",
    "            iteration=i,\n",
    "        )\n",
    "        fig_reward, ax_reward = plotter.plot_samples(torch.Tensor(samples), ax_reward, fig_reward)\n",
    "        ax_reward.set_title(\"reward fn + proposed samples of iteration %i\" % i)\n",
    "        logger.log_figure(fig_reward, \"reward\")\n",
    "\n",
    "    # Selector\n",
    "    # selector = Selector(\n",
    "    #     device=device,\n",
    "    #     float_precision=float_prec,\n",
    "    # )\n",
    "    selector = ScoreSelector(\n",
    "        acq_fn,\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "        maximize=True,\n",
    "    )\n",
    "    filtered_samples, selected_idcs = selector(n_samples=n_samples, candidate_set=dataset_handler.get_custom_dataset(torch.Tensor(samples)), index_set=sample_idcs)\n",
    "    filtered_samples = torch.Tensor(filtered_samples)\n",
    "\n",
    "    if plotter is not None:\n",
    "        x, y = train_data.dataset.get_raw_item()\n",
    "        fig_surrogate, ax_surrogate = plt.subplots(ncols=2, figsize=(15, 7))\n",
    "        plotter.plot_function(\n",
    "            surrogate.get_predictions,\n",
    "            candidate_set[:],\n",
    "            xi=xi,\n",
    "            yi=yi,\n",
    "            output_index=0,\n",
    "            fig=fig_surrogate,\n",
    "            ax=ax_surrogate[0],\n",
    "            label=\"pred_target_mean\",\n",
    "            iteration=i,\n",
    "        )\n",
    "        plotter.plot_samples(x, ax=ax_surrogate[0], fig=fig_surrogate, targets=y)\n",
    "        ax_surrogate[0].set_title(\"predicted mean + train data of iteration %i\" % i)\n",
    "        plotter.plot_function(\n",
    "            surrogate.get_predictions,\n",
    "            candidate_set[:],\n",
    "            xi=xi,\n",
    "            yi=yi,\n",
    "            output_index=1,\n",
    "            fig=fig_surrogate,\n",
    "            ax=ax_surrogate[1],\n",
    "            label=\"pred_target_var\",\n",
    "            iteration=i,\n",
    "        )\n",
    "        plotter.plot_samples(x, ax=ax_surrogate[1], fig=fig_surrogate, targets=y)\n",
    "        ax_surrogate[1].set_title(\"predicted var + train data of iteration %i\" % i)\n",
    "        logger.log_figure(fig_surrogate, \"surrogate\")\n",
    "\n",
    "    if plotter is not None:\n",
    "        fig_acq, ax_acq = plotter.plot_function(\n",
    "            acq_fn,\n",
    "            candidate_set[:],\n",
    "            xi=xi,\n",
    "            yi=yi,\n",
    "            label=\"acq\",\n",
    "            iteration=i,\n",
    "        )\n",
    "        fig_acq, ax_acq = plotter.plot_samples(filtered_samples, ax_acq, fig_acq)\n",
    "        ax_acq.set_title(\"acquisition fn + selected samples of iteration %i\" % i)\n",
    "        logger.log_figure(fig_acq, \"acq\")\n",
    "\n",
    "    if plotter is not None:\n",
    "        ax_oracle.scatter(\n",
    "            x=filtered_samples[:, 1].cpu(),\n",
    "            y=filtered_samples[:, 0].cpu(),\n",
    "            c=cm.to_hex(colors(i / n_iterations)),\n",
    "            marker=\"x\",\n",
    "            label=\"it %i\" % i,\n",
    "        )\n",
    "    \n",
    "    scores = oracle(dataset_handler.get_custom_dataset(filtered_samples)[:]).cpu()\n",
    "    scores = dataset_handler.update_dataset(filtered_samples, scores)\n",
    "    best_scores.append(scores.max())\n",
    "    all_scores[i] = scores\n",
    "    if logger is not None:\n",
    "        scores_flat = torch.stack(list(all_scores.values())).flatten()\n",
    "        logger.log_metric(scores_flat.max(), \"top_score\")\n",
    "        mean_top_k = (scores_flat\n",
    "            .topk(n_samples, largest=True)\n",
    "            .values.mean()\n",
    "        )\n",
    "        logger.log_metric(mean_top_k, \"mean_topk_score\")\n",
    "        logger.log_metric(scores.max(), \"best_score\")\n",
    "        logger.log_step(i)\n",
    "\n",
    "    if plotter is not None:\n",
    "        plotter.plot_scores(selected_idcs=selected_idcs, scores=scores, i=i+1)\n",
    "\n",
    "if ax_oracle is not None:\n",
    "    fig_oracle.legend()\n",
    "    ax_oracle.set_title(\"oracle fn + samples\")\n",
    "    logger.log_figure(fig_oracle, key=\"oracle\")\n",
    "\n",
    "if plotter is not None:\n",
    "    plotter.end(filename=\"branin.csv\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(best_scores)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"scores\")\n",
    "plt.title(\"Best Score in each iteration\")\n",
    "if logger is not None:\n",
    "    logger.log_figure(fig, key=\"best_scores\")\n",
    "    logger.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000, -0.9798],\n",
       "         [-0.9798, -0.1717],\n",
       "         [-0.1313, -1.0000],\n",
       "         [ 0.6768,  0.6970]]),\n",
       " tensor([1.0000, 0.3512, 0.0000, 0.4139]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.1313, -1.0000]],\n",
       " \n",
       "         [[ 0.6768,  0.6970]],\n",
       " \n",
       "         [[-0.9798, -0.1717]],\n",
       " \n",
       "         [[-1.0000, -0.9798]]]),\n",
       " tensor([0.0000, 0.4139, 0.3512, 1.0000])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.dataset[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test individual components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'test_branin.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  grid_size: 100\n",
      "  normalize_scores: true\n",
      "  train_fraction: 1.0\n",
      "  batch_size: 16\n",
      "  shuffle: true\n",
      "  train_path: ~/activelearning/data/branin/data_100_train.csv\n",
      "  test_path: null\n",
      "  _target_: activelearning.dataset.grid.BraninDatasetHandler\n",
      "oracle:\n",
      "  _target_: activelearning.oracle.oracle.BraninOracle\n",
      "  fidelity: 1\n",
      "  do_domain_map: true\n",
      "  negate: false\n",
      "sampler:\n",
      "  conf:\n",
      "    env:\n",
      "      _target_: gflownet.envs.grid.Grid\n",
      "      env_id: env\n",
      "      fixed_distr_params: null\n",
      "      random_distr_params: null\n",
      "      skip_mask_check: false\n",
      "      conditional: false\n",
      "      continuous: false\n",
      "      buffer:\n",
      "        replay_capacity: 0\n",
      "        train: null\n",
      "        test: null\n",
      "      id: grid\n",
      "      func: corners\n",
      "      n_dim: 2\n",
      "      length: 100\n",
      "      max_increment: 1\n",
      "      max_dim_per_action: 1\n",
      "      cell_min: -1\n",
      "      cell_max: 1\n",
      "    policy:\n",
      "      forward:\n",
      "        _target_: gflownet.policy.base.Policy\n",
      "        config:\n",
      "          type: mlp\n",
      "          n_hid: 2048\n",
      "          n_layers: 2\n",
      "          checkpoint: null\n",
      "          reload_ckpt: false\n",
      "          is_model: false\n",
      "      backward:\n",
      "        _target_: gflownet.policy.base.Policy\n",
      "        config: null\n",
      "      shared: null\n",
      "    agent:\n",
      "      _target_: gflownet.gflownet.GFlowNetAgent\n",
      "      seed: 0\n",
      "      optimizer:\n",
      "        z_dim: 16\n",
      "        loss: trajectorybalance\n",
      "        lr: 0.0005\n",
      "        lr_decay_period: 1000000\n",
      "        lr_decay_gamma: 0.5\n",
      "        lr_z_mult: 20\n",
      "        method: adam\n",
      "        early_stopping: 0.0\n",
      "        ema_alpha: 0.5\n",
      "        adam_beta1: 0.9\n",
      "        adam_beta2: 0.999\n",
      "        sgd_momentum: 0.9\n",
      "        batch_size:\n",
      "          forward: 16\n",
      "          backward_dataset: 0\n",
      "          backward_replay: 0\n",
      "        train_to_sample_ratio: 1\n",
      "        n_train_steps: 500\n",
      "        bootstrap_tau: 0.0\n",
      "        clip_grad_norm: 0.0\n",
      "      batch_reward: true\n",
      "      mask_invalid_actions: true\n",
      "      temperature_logits: 1.0\n",
      "      random_action_prob: 0.0\n",
      "      pct_offline: 0.0\n",
      "      replay_capacity: 0\n",
      "      replay_sampling: permutation\n",
      "      train_sampling: permutation\n",
      "      num_empirical_loss: 200000\n",
      "      oracle:\n",
      "        'n': 50\n",
      "      sample_only: false\n",
      "      active_learning: false\n",
      "      buffer:\n",
      "        train: null\n",
      "        test: null\n",
      "    logger:\n",
      "      _target_: gflownet.utils.logger.Logger\n",
      "      do:\n",
      "        online: false\n",
      "        times: false\n",
      "      project_name: test_gflownet\n",
      "      train:\n",
      "        period: 1\n",
      "      test:\n",
      "        first_it: true\n",
      "        period: 1000\n",
      "        'n': 100\n",
      "        kde:\n",
      "          bandwidth: 0.1\n",
      "          kernel: gaussian\n",
      "        n_top_k: 5000\n",
      "        top_k: 100\n",
      "        top_k_period: -1\n",
      "        n_trajs_logprobs: 10\n",
      "        logprobs_batch_size: 100\n",
      "        logprobs_bootstrap_size: 10000\n",
      "        max_data_logprobs: 100000.0\n",
      "        n_grid: 40000\n",
      "      oracle:\n",
      "        period: 100000\n",
      "        k:\n",
      "        - 1\n",
      "        - 10\n",
      "        - 100\n",
      "      checkpoints:\n",
      "        period: 1000\n",
      "      logdir:\n",
      "        root: activelearning/gflownet/logs\n",
      "        ckpts: activelearning/gflownetckpts\n",
      "        overwrite: true\n",
      "      debug: false\n",
      "      lightweight: false\n",
      "      progress: true\n",
      "      context: '0'\n",
      "      notes: null\n",
      "      tags:\n",
      "      - gflownet\n",
      "      run_name: identity_lr5e-4\n",
      "    proxy:\n",
      "      _target_: activelearning.sampler.proxy.AcquisitionProxy\n",
      "      reward_function: power\n",
      "      logreward_function: null\n",
      "      reward_function_kwargs:\n",
      "        beta: 1.0\n",
      "      reward_min: 1.0e-08\n",
      "      do_clip_rewards: false\n",
      "    state_flow: null\n",
      "  _target_: activelearning.sampler.sampler.RandomGFlowNetSampler\n",
      "selector:\n",
      "  _target_: activelearning.selector.selector.ScoreSelector\n",
      "surrogate:\n",
      "  _target_: activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor\n",
      "acquisition:\n",
      "  _target_: activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition\n",
      "  acq_fn_class:\n",
      "    _target_: botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy\n",
      "    _partial_: true\n",
      "user:\n",
      "  logdir:\n",
      "    root: ./logs\n",
      "  data:\n",
      "    root: ./data\n",
      "logger:\n",
      "  _target_: activelearning.utils.logger.WandBLogger\n",
      "  project_name: test_branin\n",
      "  run_name: ${dataset.grid_size}_gflownet_gp_mve\n",
      "device: cpu\n",
      "float_precision: 32\n",
      "budget: 10\n",
      "n_samples: 5\n",
      "seed: 31415\n",
      "maximize: false\n",
      "\n",
      "{'dataset': {'grid_size': 100, 'normalize_scores': True, 'train_fraction': 1.0, 'batch_size': 16, 'shuffle': True, 'train_path': '~/activelearning/data/branin/data_100_train.csv', 'test_path': None, '_target_': 'activelearning.dataset.grid.BraninDatasetHandler'}, 'oracle': {'_target_': 'activelearning.oracle.oracle.BraninOracle', 'fidelity': 1, 'do_domain_map': True, 'negate': False}, 'sampler': {'conf': {'env': {'_target_': 'gflownet.envs.grid.Grid', 'env_id': 'env', 'fixed_distr_params': None, 'random_distr_params': None, 'skip_mask_check': False, 'conditional': False, 'continuous': False, 'buffer': {'replay_capacity': 0, 'train': None, 'test': None}, 'id': 'grid', 'func': 'corners', 'n_dim': 2, 'length': 100, 'max_increment': 1, 'max_dim_per_action': 1, 'cell_min': -1, 'cell_max': 1}, 'policy': {'forward': {'_target_': 'gflownet.policy.base.Policy', 'config': {'type': 'mlp', 'n_hid': 2048, 'n_layers': 2, 'checkpoint': None, 'reload_ckpt': False, 'is_model': False}}, 'backward': {'_target_': 'gflownet.policy.base.Policy', 'config': None}, 'shared': None}, 'agent': {'_target_': 'gflownet.gflownet.GFlowNetAgent', 'seed': 0, 'optimizer': {'z_dim': 16, 'loss': 'trajectorybalance', 'lr': 0.0005, 'lr_decay_period': 1000000, 'lr_decay_gamma': 0.5, 'lr_z_mult': 20, 'method': 'adam', 'early_stopping': 0.0, 'ema_alpha': 0.5, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'sgd_momentum': 0.9, 'batch_size': {'forward': 16, 'backward_dataset': 0, 'backward_replay': 0}, 'train_to_sample_ratio': 1, 'n_train_steps': 500, 'bootstrap_tau': 0.0, 'clip_grad_norm': 0.0}, 'batch_reward': True, 'mask_invalid_actions': True, 'temperature_logits': 1.0, 'random_action_prob': 0.0, 'pct_offline': 0.0, 'replay_capacity': 0, 'replay_sampling': 'permutation', 'train_sampling': 'permutation', 'num_empirical_loss': 200000, 'oracle': {'n': 50}, 'sample_only': False, 'active_learning': False, 'buffer': {'train': None, 'test': None}}, 'logger': {'_target_': 'gflownet.utils.logger.Logger', 'do': {'online': False, 'times': False}, 'project_name': 'test_gflownet', 'train': {'period': 1}, 'test': {'first_it': True, 'period': 1000, 'n': 100, 'kde': {'bandwidth': 0.1, 'kernel': 'gaussian'}, 'n_top_k': 5000, 'top_k': 100, 'top_k_period': -1, 'n_trajs_logprobs': 10, 'logprobs_batch_size': 100, 'logprobs_bootstrap_size': 10000, 'max_data_logprobs': 100000.0, 'n_grid': 40000}, 'oracle': {'period': 100000, 'k': [1, 10, 100]}, 'checkpoints': {'period': 1000}, 'logdir': {'root': 'activelearning/gflownet/logs', 'ckpts': 'activelearning/gflownetckpts', 'overwrite': True}, 'debug': False, 'lightweight': False, 'progress': True, 'context': '0', 'notes': None, 'tags': ['gflownet'], 'run_name': 'identity_lr5e-4'}, 'proxy': {'_target_': 'activelearning.sampler.proxy.AcquisitionProxy', 'reward_function': 'power', 'logreward_function': None, 'reward_function_kwargs': {'beta': 1.0}, 'reward_min': 1e-08, 'do_clip_rewards': False}, 'state_flow': None}, '_target_': 'activelearning.sampler.sampler.RandomGFlowNetSampler'}, 'selector': {'_target_': 'activelearning.selector.selector.ScoreSelector'}, 'surrogate': {'_target_': 'activelearning.surrogate.gp_surrogate.SingleTaskGPRegressor'}, 'acquisition': {'_target_': 'activelearning.acquisition.acquisition.BOTorchMaxValueEntropyAcquisition', 'acq_fn_class': {'_target_': 'botorch.acquisition.max_value_entropy_search.qLowerBoundMaxValueEntropy', '_partial_': True}}, 'user': {'logdir': {'root': './logs'}, 'data': {'root': './data'}}, 'logger': {'_target_': 'activelearning.utils.logger.WandBLogger', 'project_name': 'test_branin', 'run_name': '${dataset.grid_size}_gflownet_gp_mve'}, 'device': 'cpu', 'float_precision': 32, 'budget': 10, 'n_samples': 5, 'seed': 31415, 'maximize': False}\n"
     ]
    }
   ],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config = compose(config_name=\"test_branin.yaml\", overrides=[])\n",
    "    print(OmegaConf.to_yaml(config))\n",
    "    print(config)\n",
    "\n",
    "config.sampler.conf.logger.do.online = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = config.device\n",
    "n_iterations = config.budget  # TODO: replace with budget\n",
    "grid_size = config.env.length\n",
    "n_samples = config.n_samples\n",
    "\n",
    "from gflownet.utils.common import set_float_precision\n",
    "float_prec = set_float_precision(config.float_precision)\n",
    "# float_prec = set_float_precision(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    }
   ],
   "source": [
    "from activelearning.dataset.grid import BraninDatasetHandler\n",
    "from activelearning.surrogate.gp_surrogate import SingleTaskGPRegressor\n",
    "from activelearning.acquisition.acquisition import BOTorchMaxValueEntropyAcquisition\n",
    "from activelearning.oracle.oracle import BraninOracle\n",
    "\n",
    "# Dataset\n",
    "dataset_handler = BraninDatasetHandler(\n",
    "    grid_size=100,\n",
    "    train_path=\"./data/branin/data_%i_train.csv\" % 100,\n",
    "    train_fraction=1.0,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "\n",
    "train_data, test_data = dataset_handler.get_dataloader()\n",
    "# Surrogate (e.g., Bayesian Optimization)\n",
    "# starts with a clean slate each iteration\n",
    "surrogate = SingleTaskGPRegressor(\n",
    "    device=device,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "surrogate.fit(train_data)\n",
    "\n",
    "acq_fn = BOTorchMaxValueEntropyAcquisition(\n",
    "    surrogate.model, device=device, float_precision=float_prec\n",
    ")\n",
    "\n",
    "# Oracle\n",
    "oracle = BraninOracle(\n",
    "    fidelity=1, do_domain_map=True, device=device, float_precision=float_prec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env': {'_target_': 'gflownet.envs.grid.Grid', 'env_id': 'env', 'fixed_distr_params': None, 'random_distr_params': None, 'skip_mask_check': False, 'conditional': False, 'continuous': False, 'buffer': {'replay_capacity': 0, 'train': None, 'test': None}, 'id': 'grid', 'func': 'corners', 'n_dim': 2, 'length': 100, 'max_increment': 1, 'max_dim_per_action': 1, 'cell_min': -1, 'cell_max': 1}, 'policy': {'forward': {'_target_': 'gflownet.policy.base.Policy', 'config': {'type': 'mlp', 'n_hid': 2048, 'n_layers': 2, 'checkpoint': None, 'reload_ckpt': False, 'is_model': False}}, 'backward': {'_target_': 'gflownet.policy.base.Policy', 'config': None}, 'shared': None}, 'agent': {'_target_': 'gflownet.gflownet.GFlowNetAgent', 'seed': 0, 'optimizer': {'z_dim': 16, 'loss': 'trajectorybalance', 'lr': 0.0005, 'lr_decay_period': 1000000, 'lr_decay_gamma': 0.5, 'lr_z_mult': 20, 'method': 'adam', 'early_stopping': 0.0, 'ema_alpha': 0.5, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'sgd_momentum': 0.9, 'batch_size': {'forward': 16, 'backward_dataset': 0, 'backward_replay': 0}, 'train_to_sample_ratio': 1, 'n_train_steps': 500, 'bootstrap_tau': 0.0, 'clip_grad_norm': 0.0}, 'batch_reward': True, 'mask_invalid_actions': True, 'temperature_logits': 1.0, 'random_action_prob': 0.0, 'pct_offline': 0.0, 'replay_capacity': 0, 'replay_sampling': 'permutation', 'train_sampling': 'permutation', 'num_empirical_loss': 200000, 'oracle': {'n': 50}, 'sample_only': False, 'active_learning': False, 'buffer': {'train': None, 'test': None}}, 'logger': {'_target_': 'gflownet.utils.logger.Logger', 'do': {'online': False, 'times': False}, 'project_name': 'test_gflownet', 'train': {'period': 1}, 'test': {'first_it': True, 'period': 1000, 'n': 100, 'kde': {'bandwidth': 0.1, 'kernel': 'gaussian'}, 'n_top_k': 5000, 'top_k': 100, 'top_k_period': -1, 'n_trajs_logprobs': 10, 'logprobs_batch_size': 100, 'logprobs_bootstrap_size': 10000, 'max_data_logprobs': 100000.0, 'n_grid': 40000}, 'oracle': {'period': 100000, 'k': [1, 10, 100]}, 'checkpoints': {'period': 1000}, 'logdir': {'root': 'activelearning/gflownet/logs', 'ckpts': 'activelearning/gflownetckpts', 'overwrite': True}, 'debug': False, 'lightweight': False, 'progress': True, 'context': '0', 'notes': None, 'tags': ['gflownet'], 'run_name': 'identity_lr5e-4'}, 'proxy': {'_target_': 'activelearning.sampler.proxy.AcquisitionProxy', 'reward_function': 'power', 'logreward_function': None, 'reward_function_kwargs': {'beta': 1.0}, 'reward_min': 1e-08, 'do_clip_rewards': False}, 'state_flow': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.sampler.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet.envs.grid import Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_target_': 'gflownet.envs.grid.Grid', 'env_id': 'env', 'fixed_distr_params': None, 'random_distr_params': None, 'skip_mask_check': False, 'conditional': False, 'continuous': False, 'buffer': {'replay_capacity': 0, 'train': None, 'test': None}, 'id': 'grid', 'func': 'corners', 'n_dim': 2, 'length': 100, 'max_increment': 1, 'max_dim_per_action': 1, 'cell_min': -1, 'cell_max': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.sampler.conf.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sampler (e.g., GFlowNet, or Random Sampler)\n",
    "sampler = hydra.utils.instantiate(\n",
    "    config.sampler,\n",
    "    acquisition=acq_fn,\n",
    "    device=device,\n",
    "    float_precision=float_prec,\n",
    "    _recursive_=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/mila/c/christina.humer/.conda/envs/al_new/lib/python3.10/site-packages/gflownet/utils/buffer.py:140: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.main = pd.concat(\n",
      "Loss: 2095.3161 | Mean rewards: -0.08 | JSD: -1.0000: 100%|██████████| 100/100 [00:09<00:00, 10.41it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler.fit()  # only necessary for samplers that train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0100, 0.0000],\n",
       "        [0.0000, 0.0100],\n",
       "        [0.0100, 0.0000],\n",
       "        [0.0100, 0.0000],\n",
       "        [0.0100, 0.0000],\n",
       "        [0.0200, 0.0000],\n",
       "        [0.0000, 0.0200],\n",
       "        [0.0100, 0.0100],\n",
       "        [0.0000, 0.0200],\n",
       "        [0.0000, 0.0200],\n",
       "        [0.0100, 0.0200],\n",
       "        [0.0100, 0.0200]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples, sample_idcs = sampler.get_samples(\n",
    "    n_samples * 5, candidate_set=None\n",
    ")\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet.envs.grid import Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 0), (0, 0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_env = Grid(2, 10, 1, 1, -1, 1)\n",
    "grid_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 4], [4, 0], [8, 8]]\n",
      "tensor([[0., 0.],\n",
      "        [0., 4.],\n",
      "        [4., 0.],\n",
      "        [8., 8.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000],\n",
       "        [-1.0000, -0.1111],\n",
       "        [-0.1111, -1.0000],\n",
       "        [ 0.7778,  0.7778]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_env.states2proxy([[0, 0], [0, 4], [4, 0], [8, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "        0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_env.cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "from gflownet.utils.common import set_float_precision\n",
    "float_prec = set_float_precision(64)\n",
    "# float_prec = torch.double\n",
    "\n",
    "import numpy as np\n",
    "grid_size = 10  # 100\n",
    "test_states = torch.tensor([[0.5, 0.5]])\n",
    "test_scores = torch.tensor([-150.0])\n",
    "n_samples = 5\n",
    "\n",
    "baseline_states = torch.tensor(\n",
    "    [\n",
    "        [0.0 * grid_size, 0.0 * grid_size],\n",
    "        [0.0 * grid_size, 0.4 * grid_size],\n",
    "        [0.4 * grid_size, 0.0 * grid_size],\n",
    "        [0.8 * grid_size, 0.8 * grid_size],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define grid space\n",
    "xi = np.arange(0, 1, 1 / grid_size)\n",
    "yi = np.arange(0, 1, 1 / grid_size)\n",
    "grid = np.array(np.meshgrid(xi, yi))\n",
    "grid_flat = torch.tensor(grid.T, dtype=float_prec).reshape(-1, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "from dataset.dataset import BraninDatasetHandler\n",
    "\n",
    "dataset_handler = BraninDatasetHandler(\n",
    "    grid_size=grid_size,\n",
    "    train_path=\"./storage/branin/data_%i_train.csv\" % grid_size,\n",
    "    train_fraction=1.0,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "\n",
    "# testing dataset\n",
    "dataset_handler.update_dataset(test_states, test_scores)\n",
    "print(dataset_handler.train_data.X_data, dataset_handler.train_data.y_data)\n",
    "print(dataset_handler.train_data[:])\n",
    "train_loader, test_loader = dataset_handler.get_dataloader()\n",
    "for X, y in train_loader:\n",
    "    print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oracle\n",
    "from gflownet.proxy.box.branin import Branin\n",
    "\n",
    "oracle = Branin(fidelity=1, do_domain_map=True, device=device, float_precision=float_prec)\n",
    "\n",
    "# testing oracle\n",
    "print(oracle(baseline_states.to(device).clone() / grid_size))\n",
    "\n",
    "# plot oracle function\n",
    "plot_function(oracle, grid_flat.clone(), scatter_markers=baseline_states / grid_size)\n",
    "plt.title(\"Oracle function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surrogate (e.g., Bayesian Optimization)\n",
    "from surrogate.surrogate import SingleTaskGPRegressor\n",
    "\n",
    "surrogate = SingleTaskGPRegressor(device=device, float_precision=float_prec)\n",
    "train_data, test_data = dataset_handler.get_dataloader()\n",
    "surrogate.fit(train_data)\n",
    "\n",
    "# testing surrogate\n",
    "preds_mean, preds_var = surrogate.get_predictions(test_states / grid_size)\n",
    "print(preds_mean, preds_var)\n",
    "\n",
    "# plot surrogate functions\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 4))\n",
    "\n",
    "plot_function(\n",
    "    surrogate.get_predictions,\n",
    "    grid_flat.clone(),\n",
    "    fig=fig,\n",
    "    ax=axes[0],\n",
    "    scatter_markers=baseline_states / grid_size,\n",
    "    output_index=0,\n",
    ")\n",
    "axes[0].set_title(\"estimated mean\")\n",
    "\n",
    "plot_function(\n",
    "    surrogate.get_predictions,\n",
    "    grid_flat.clone(),\n",
    "    fig=fig,\n",
    "    ax=axes[1],\n",
    "    scatter_markers=baseline_states / grid_size,\n",
    "    output_index=1,\n",
    ")\n",
    "axes[1].set_title(\"uncertainty\")\n",
    "\n",
    "plot_function(\n",
    "    surrogate.get_acquisition_values,\n",
    "    grid_flat.clone(),\n",
    "    fig=fig,\n",
    "    ax=axes[2],\n",
    "    scatter_markers=baseline_states / grid_size,\n",
    ")\n",
    "axes[2].set_title(\"acquisition function\")\n",
    "\n",
    "fig.suptitle(\"Surrogate Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler (e.g., GFlowNet, or Random Sampler)\n",
    "from sampler.sampler import GreedySampler, RandomSampler\n",
    "\n",
    "sampler = GreedySampler(surrogate)\n",
    "# sampler = RandomSampler(surrogate)\n",
    "sampler.fit()\n",
    "samples, _ = sampler.get_samples(n_samples * 3, grid_flat.clone()).cpu()\n",
    "\n",
    "# plot acq function with proposed candidates\n",
    "fig, ax = plot_function(\n",
    "    surrogate.get_acquisition_values, grid_flat.clone(), scatter_markers=samples\n",
    ")\n",
    "plt.title(\"Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq = surrogate.get_acquisition_values(grid_flat.clone()).detach().cpu()\n",
    "plt.matshow(acq.reshape(int(len(acq) ** (1 / 2)), int(len(acq) ** (1 / 2))))\n",
    "plt.scatter(samples.cpu()[:, 1] * grid_size, samples.cpu()[:, 0] * grid_size)\n",
    "plt.scatter(baseline_states[:, 1].cpu(), baseline_states[:, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter.filter import Filter, ScoreFilter\n",
    "\n",
    "filter = Filter()\n",
    "# filter = OracleFilter(oracle)\n",
    "filtered_samples = filter(n_samples, samples)\n",
    "\n",
    "# plot oracle function with proposed candidates\n",
    "fig, ax = plot_function(\n",
    "    surrogate.get_acquisition_values,\n",
    "    grid_flat.clone(),\n",
    "    scatter_markers=filtered_samples.to(\"cpu\"),\n",
    ")\n",
    "plt.title(\"Proposed Candidates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFlowNet Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "float_prec = torch.float32\n",
    "device = \"cpu\"\n",
    "grid_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "from dataset.dataset import BraninDatasetHandler\n",
    "\n",
    "dataset_handler = BraninDatasetHandler(\n",
    "    grid_size=grid_size,\n",
    "    train_path=\"./storage/branin/data_%i_train.csv\" % grid_size,\n",
    "    train_fraction=1.0,\n",
    "    float_precision=float_prec,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, _ = dataset_handler.get_dataloader()\n",
    "for r in train_data:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  # Python 3.4+\n",
    "import surrogate.surrogate as surrogate\n",
    "\n",
    "reload(surrogate)\n",
    "\n",
    "from surrogate.surrogate import SingleTaskGPRegressor\n",
    "\n",
    "surrogate = SingleTaskGPRegressor(device=device, float_precision=float_prec, maximize=False)\n",
    "train_data, test_data = dataset_handler.get_dataloader()\n",
    "surrogate.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config_logger = compose(config_name=\"logger/wandb.yaml\", overrides=[])\n",
    "    # print(OmegaConf.to_yaml(env_config))\n",
    "    print(config_logger)\n",
    "\n",
    "logger = hydra.utils.instantiate(config_logger.logger, config_logger, _recursive_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config_logger = compose(config_name=\"logger/wandb.yaml\", overrides=[])\n",
    "    # print(OmegaConf.to_yaml(env_config))\n",
    "    print(config_logger)\n",
    "\n",
    "# Logger\n",
    "# from utils.logger import Logger\n",
    "\n",
    "# logger = Logger(config=OmegaConf.create(), **config_logger)\n",
    "logger = hydra.utils.instantiate(config_logger.logger, config_logger, _recursive_=False)\n",
    "\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config_sampler = compose(config_name=\"sampler/gflownet.yaml\", overrides=[])\n",
    "    # print(OmegaConf.to_yaml(config_sampler))\n",
    "    print(config_sampler)\n",
    "\n",
    "grid_env = hydra.utils.instantiate(\n",
    "    config_sampler.sampler.conf.env,\n",
    "    proxy=surrogate,\n",
    "    device=device,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "\n",
    "# The policy is used to model the probability of a forward/backward action\n",
    "forward_policy = hydra.utils.instantiate(\n",
    "    config_sampler.sampler.conf.policy.forward,\n",
    "    env=grid_env,\n",
    "    device=device,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "backward_policy = hydra.utils.instantiate(\n",
    "    config_sampler.sampler.conf.policy.backward,\n",
    "    env=grid_env,\n",
    "    device=device,\n",
    "    float_precision=float_prec,\n",
    ")\n",
    "\n",
    "# State flow\n",
    "if config_sampler.sampler.conf.state_flow is not None:\n",
    "    state_flow = hydra.utils.instantiate(\n",
    "        config_sampler.sampler.conf.state_flow,\n",
    "        env=grid_env,\n",
    "        device=device,\n",
    "        float_precision=float_prec,\n",
    "        base=forward_policy,\n",
    "    )\n",
    "else:\n",
    "    state_flow = None\n",
    "\n",
    "# GFlowNet Agent\n",
    "sampler = hydra.utils.instantiate(\n",
    "    config_sampler.sampler.conf.agent,\n",
    "    device=device,\n",
    "    float_precision=float_prec,\n",
    "    env=grid_env,\n",
    "    forward_policy=forward_policy,\n",
    "    backward_policy=backward_policy,\n",
    "    state_flow=state_flow,\n",
    "    buffer=config_sampler.sampler.conf.env.buffer,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, times = sampler.sample_batch(n_forward=10, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.get_terminating_states(proxy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config_sampler = compose(config_name=\"sampler/gflownet.yaml\", overrides=[])\n",
    "    # print(OmegaConf.to_yaml(config_sampler))\n",
    "    print(config_sampler)\n",
    "    \n",
    "sampler = hydra.utils.instantiate(\n",
    "    config_sampler.sampler,\n",
    "    surrogate=surrogate,\n",
    "    logger=logger,\n",
    "    device=device,\n",
    "    float_precision=float_prec,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, _ = sampler.get_samples(n_samples * 3, grid_flat.clone()).cpu()\n",
    "\n",
    "# plot acq function with proposed candidates\n",
    "fig, ax = plot_function(\n",
    "    surrogate.get_acquisition_values, grid_flat.clone(), scatter_markers=samples\n",
    ")\n",
    "plt.title(\"Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampler.sampler import GFlowNetSampler\n",
    "\n",
    "sampler = GFlowNetSampler(surrogate, config_sampler, logger, device, float_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logger\n",
    "# from utils.logger import Logger\n",
    "\n",
    "# logger = Logger(config=OmegaConf.create(), **config_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet.envs.grid import Grid as GFlowNetGridEnv\n",
    "\n",
    "grid_env = GFlowNetGridEnv(\n",
    "    n_dim=2,\n",
    "    length=grid_size,\n",
    "    max_increment=1,\n",
    "    max_dim_per_action=1,\n",
    "    cell_min=0,\n",
    "    cell_max=1,\n",
    "    proxy=surrogate,\n",
    "    reward_func=\"identity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hydra config in notebooks\n",
    "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
    "import os\n",
    "from hydra import initialize_config_dir, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "abs_config_dir = os.path.abspath(\"config/\")\n",
    "with initialize_config_dir(version_base=None, config_dir=abs_config_dir):\n",
    "    config_gflownet = compose(config_name=\"gflownet.yaml\", overrides=[])\n",
    "    # print(OmegaConf.to_yaml(env_config))\n",
    "    print(config_gflownet)\n",
    "\n",
    "# GFlowNetAgent\n",
    "from gflownet.policy.base import Policy\n",
    "from gflownet.gflownet import GFlowNetAgent\n",
    "\n",
    "forward_policy = Policy(\n",
    "    config_gflownet.policy.forward,\n",
    "    env=grid_env,\n",
    "    device=device,\n",
    "    float_precision=torch.double,\n",
    ")\n",
    "\n",
    "backward_policy = Policy(\n",
    "    config_gflownet.policy.backward,\n",
    "    env=grid_env,\n",
    "    device=device,\n",
    "    float_precision=torch.double,\n",
    ")\n",
    "\n",
    "sampler = GFlowNetAgent(\n",
    "    grid_env,\n",
    "    device=device,\n",
    "    float_precision=torch.double,\n",
    "    forward_policy=forward_policy,\n",
    "    backward_policy=backward_policy,\n",
    "    logger=logger,\n",
    "    **config_gflownet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet.utils.batch import Batch\n",
    "batch = Batch(env=grid_env, device=device, float_type=float_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make indices of batch consecutive since they are used for indexing here\n",
    "# Get necessary tensors from batch\n",
    "states_policy = batch.get_states(policy=True)\n",
    "states = batch.get_states(policy=False)\n",
    "actions = batch.get_actions()\n",
    "parents_policy = batch.get_parents(policy=True)\n",
    "parents = batch.get_parents(policy=False)\n",
    "traj_indices = batch.get_trajectory_indices(consecutive=True)\n",
    "# Forward trajectories\n",
    "masks_f = batch.get_masks_forward(of_parents=True)\n",
    "policy_output_f = forward_policy(parents_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # environment\n",
    "# import config\n",
    "# train = config.env.BufferSpec(\n",
    "#     path=\"~/scratch/datasets/grid/corners_d2l3_r0.csv\",\n",
    "#     seed=167,\n",
    "#     n=1000,\n",
    "# )\n",
    "# test = config.env.BufferSpec(\n",
    "#     path=\"~/scratch/datasets/grid/corners_d2l3_r0.csv\",\n",
    "#     seed=167,\n",
    "#     n=1000,\n",
    "# )\n",
    "# buffer = config.env.Buffer(train=train, test=test)\n",
    "# config_env = config.env.Grid_Env(\n",
    "#     buffer,\n",
    "#     min_step_len=1,\n",
    "#     max_step_len=1,\n",
    "#     cell_min=-1,\n",
    "#     cell_max=1\n",
    "# )\n",
    "\n",
    "# from environment.grid_env import GridEnv\n",
    "# env = GridEnv(**config_env.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
